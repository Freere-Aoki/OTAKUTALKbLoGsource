{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/head-img/QQ图片20210320214654.png","path":"head-img/QQ图片20210320214654.png","modified":0,"renderable":0},{"_id":"source/head-img/head.png","path":"head-img/head.png","modified":0,"renderable":0},{"_id":"source/img/20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png","path":"img/20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png","modified":0,"renderable":0},{"_id":"source/img/202005241421367251716257711.500x0.jpg.webp","path":"img/202005241421367251716257711.500x0.jpg.webp","modified":0,"renderable":0},{"_id":"source/img/20200811145254657.png","path":"img/20200811145254657.png","modified":0,"renderable":0},{"_id":"source/img/20200811154500211.png","path":"img/20200811154500211.png","modified":0,"renderable":0},{"_id":"source/img/20200811154704891.png","path":"img/20200811154704891.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210312144133.png","path":"img/QQ截图20210312144133.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210312145034.png","path":"img/QQ截图20210312145034.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210312145927.png","path":"img/QQ截图20210312145927.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210312150624.png","path":"img/QQ截图20210312150624.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210312160137.png","path":"img/QQ截图20210312160137.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210315093653.png","path":"img/QQ截图20210315093653.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210315100337.png","path":"img/QQ截图20210315100337.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210315135813.png","path":"img/QQ截图20210315135813.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210315150441.png","path":"img/QQ截图20210315150441.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210317173744.png","path":"img/QQ截图20210317173744.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318111958.png","path":"img/QQ截图20210318111958.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318164049.png","path":"img/QQ截图20210318164049.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318164346.png","path":"img/QQ截图20210318164346.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318164227.png","path":"img/QQ截图20210318164227.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318170041.png","path":"img/QQ截图20210318170041.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318170601.png","path":"img/QQ截图20210318170601.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318170649.png","path":"img/QQ截图20210318170649.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210318171011.png","path":"img/QQ截图20210318171011.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319085849.png","path":"img/QQ截图20210319085849.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319085415.png","path":"img/QQ截图20210319085415.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319090259.png","path":"img/QQ截图20210319090259.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319090825.png","path":"img/QQ截图20210319090825.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319090340.png","path":"img/QQ截图20210319090340.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319091413.png","path":"img/QQ截图20210319091413.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319091622.png","path":"img/QQ截图20210319091622.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319092829.png","path":"img/QQ截图20210319092829.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319093220.png","path":"img/QQ截图20210319093220.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319093541.png","path":"img/QQ截图20210319093541.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319093607.png","path":"img/QQ截图20210319093607.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319094058.png","path":"img/QQ截图20210319094058.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210319094206.png","path":"img/QQ截图20210319094206.png","modified":0,"renderable":0},{"_id":"source/img/fdacab61d58425e368f30729feb2d2c8.jpg","path":"img/fdacab61d58425e368f30729feb2d2c8.jpg","modified":0,"renderable":0},{"_id":"themes/next/source/style.scss","path":"style.scss","modified":0,"renderable":1},{"_id":"themes/next/source/fonts/icomoon.eot","path":"fonts/icomoon.eot","modified":0,"renderable":1},{"_id":"themes/next/source/fonts/icomoon.svg","path":"fonts/icomoon.svg","modified":0,"renderable":1},{"_id":"themes/next/source/fonts/icomoon.woff","path":"fonts/icomoon.woff","modified":0,"renderable":1},{"_id":"themes/next/source/fonts/icomoon.ttf","path":"fonts/icomoon.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/img/algolia.svg","path":"img/algolia.svg","modified":0,"renderable":1},{"_id":"themes/next/source/fonts/selection.json","path":"fonts/selection.json","modified":0,"renderable":1},{"_id":"themes/next/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/next/source/img/azure.svg","path":"img/azure.svg","modified":0,"renderable":1},{"_id":"themes/next/source/img/baidu.svg","path":"img/baidu.svg","modified":0,"renderable":1},{"_id":"themes/next/source/img/logo.png","path":"img/logo.png","modified":0,"renderable":1},{"_id":"themes/next/source/img/google.svg","path":"img/google.svg","modified":0,"renderable":1},{"_id":"themes/next/source/img/logo.psd","path":"img/logo.psd","modified":0,"renderable":1},{"_id":"themes/next/source/img/sidebar-bg.png","path":"img/sidebar-bg.png","modified":0,"renderable":1},{"_id":"themes/next/source/js/jquery.fitvids.js","path":"js/jquery.fitvids.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/app.js","path":"js/app.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/jquery.min.js","path":"js/jquery.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/search.js","path":"js/search.js","modified":0,"renderable":1},{"_id":"themes/next/source/style/archive.scss","path":"style/archive.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/base.scss","path":"style/base.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/button.scss","path":"style/button.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/content.scss","path":"style/content.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/fonts.scss","path":"style/fonts.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/header.scss","path":"style/header.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/loading.scss","path":"style/loading.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/footer.scss","path":"style/footer.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/normalize.scss","path":"style/normalize.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/pagination.scss","path":"style/pagination.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/post.scss","path":"style/post.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/sidebar.scss","path":"style/sidebar.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/search.scss","path":"style/search.scss","modified":0,"renderable":1},{"_id":"themes/next/source/style/variables.scss","path":"style/variables.scss","modified":0,"renderable":1},{"_id":"source/img/2a77752309f790520f2b21421bf3d7ca7acbd5ed.gif","path":"img/2a77752309f790520f2b21421bf3d7ca7acbd5ed.gif","modified":0,"renderable":0},{"_id":"source/img/7a1c08c79f3df8dccd0ae9edda11728b461028ed.gif","path":"img/7a1c08c79f3df8dccd0ae9edda11728b461028ed.gif","modified":0,"renderable":0},{"_id":"source/img/53186325_p0.jpg","path":"img/53186325_p0.jpg","modified":0,"renderable":0},{"_id":"source/img/bbe600fa828ba61e7b3276565634970a314e593a.gif","path":"img/bbe600fa828ba61e7b3276565634970a314e593a.gif","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210322162126.png","path":"img/QQ截图20210322162126.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210322162407.png","path":"img/QQ截图20210322162407.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210322163703.png","path":"img/QQ截图20210322163703.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210322162801.png","path":"img/QQ截图20210322162801.png","modified":0,"renderable":0},{"_id":"source/img/QQ截图20210322165150.png","path":"img/QQ截图20210322165150.png","modified":0,"renderable":0},{"_id":"source/img/show.png","path":"img/show.png","modified":0,"renderable":0}],"Cache":[{"_id":"source/_drafts/test.md","hash":"63bc5315db3e698b935f6f2afc0da2b3a68d39ed","modified":1616383863375},{"_id":"source/_posts/SAP-Data-Services-Designer.md","hash":"18156d48615282bd557b9413e2aa9562dbafdad7","modified":1616400430536},{"_id":"source/_posts/hello-world.md","hash":"187a3e05d86d158ab485f73dd64833b8454e8c9e","modified":1616394929968},{"_id":"source/_posts/wHo-i-M-I.md","hash":"692f3c3e36f02d26519ac9ea25662fac13f30d0e","modified":1616138578563},{"_id":"source/_posts/开窗函数.md","hash":"8d8ca64efb0d62eab65001e345ebe5465e9f9871","modified":1616400423885},{"_id":"source/_posts/排序函数.md","hash":"42efaefc225830e54af72536a4399083af76ad16","modified":1616400427024},{"_id":"source/gunName/index.md","hash":"314da3178ceaf11dd2833a8b3c37bbb88f67372e","modified":1616397155386},{"_id":"source/about/index.md","hash":"2167562238d3df617ad15f416f4eae2292c3356e","modified":1616397089223},{"_id":"source/head-img/QQ图片20210320214654.png","hash":"4acb5505d8fe648175b103c1fba0a6273e91f1fc","modified":1616248012000},{"_id":"source/img/202005241421367251716257711.500x0.jpg.webp","hash":"dffaab9b1a7261004410113b1ad2d25083822cb2","modified":1590341665209},{"_id":"source/img/20200811154704891.png","hash":"98f52bacf840757f2196c69682e72ca89f9d65a3","modified":1616048690247},{"_id":"source/img/QQ截图20210312144133.png","hash":"227e9d2932081e42228d2c19baae6df10c29646d","modified":1615531300043},{"_id":"source/img/QQ截图20210312145034.png","hash":"0ca287359c91fcd962de1d93dd4c14269341b443","modified":1615531835803},{"_id":"source/img/QQ截图20210312145927.png","hash":"7d7fcfff4048ff873aa703e7356df6f6569c8275","modified":1615532369957},{"_id":"source/img/QQ截图20210312150624.png","hash":"00e2c5aef947fa9afa1b16aae70a384b8e67ba15","modified":1615532786129},{"_id":"source/img/QQ截图20210312160137.png","hash":"7bd34c97762e4fcf64c41e1c3aa8b02f46be464b","modified":1615536099871},{"_id":"source/img/QQ截图20210315093653.png","hash":"d926c3a8966a02e34a29370418ab430b078d1154","modified":1615772218616},{"_id":"source/img/QQ截图20210315100337.png","hash":"0d432c77ccd669cfa354ed9c4d64ba6e4e76740b","modified":1615773819141},{"_id":"source/img/QQ截图20210315135813.png","hash":"133b52dc15f610632d09a0b3ccd59148b2866e1a","modified":1615787896122},{"_id":"source/img/QQ截图20210315150441.png","hash":"eb3e413c579a75a5064be3f8ca6d2347c94f12bf","modified":1615791883502},{"_id":"source/img/QQ截图20210317173744.png","hash":"0b5ed152bce8c3f77552f3e81f7b8d99dda16fe6","modified":1615973867533},{"_id":"source/img/QQ截图20210318164227.png","hash":"0efffdbee9e25c2a82800250e303237c4c545383","modified":1616056948600},{"_id":"source/img/QQ截图20210318170041.png","hash":"48f149911d1e13a38a91e7c79fb286c9b7df127c","modified":1616058043135},{"_id":"source/img/QQ截图20210318170601.png","hash":"a8a971679c7f2fd77be98c4c6fb78242c99d2bb8","modified":1616058362834},{"_id":"source/img/QQ截图20210318170649.png","hash":"40f48dd21577d31cd6919fb2cd9b194c58d27a04","modified":1616058410649},{"_id":"source/img/QQ截图20210318171011.png","hash":"593c99385b1ec73f1dcfce273d904d3a580b0e1f","modified":1616058612800},{"_id":"source/img/QQ截图20210319085849.png","hash":"3e417272edd2df31694362e95818e88a7795d472","modified":1616115531343},{"_id":"source/img/QQ截图20210319090825.png","hash":"3e10c20f30112c3706c9fa430f6e1dbf8bb22d76","modified":1616116106432},{"_id":"source/img/QQ截图20210319090340.png","hash":"7e8c4aab5eef58113a888afd26d92a11dafef181","modified":1616115823054},{"_id":"source/img/QQ截图20210319091413.png","hash":"86c59ab9f13ff18809043efa0e46416f92ccd01f","modified":1616116454794},{"_id":"source/img/QQ截图20210319092829.png","hash":"fe8ac76dbdecdd4affca545e3ae810ee62779612","modified":1616117310674},{"_id":"source/img/QQ截图20210319093220.png","hash":"b275dd310e7a1b41a979c998242c64e7dbb392be","modified":1616117542391},{"_id":"source/img/QQ截图20210319093541.png","hash":"1d311c59adc7eca430bbc490d78002dd3beaf04f","modified":1616117743108},{"_id":"source/img/QQ截图20210319093607.png","hash":"51acf6a61c0717cd25582b98b121fc3bffcb42ca","modified":1616117770356},{"_id":"source/img/QQ截图20210319094058.png","hash":"f0cf28969ad3cfaff34837d08396e310f3620aaf","modified":1616118059562},{"_id":"source/img/QQ截图20210319094206.png","hash":"d81efe3c1f93446e35647b52e0e445e4ab13f049","modified":1616118128149},{"_id":"source/header/index.md","hash":"fea62b5a171f3b3d7c6f8e9dc3eb56990ee202d6","modified":1616397173885},{"_id":"source/img/20200811154500211.png","hash":"20d71313d6bee59c0a1921984a2732f99eb4b672","modified":1616048491576},{"_id":"source/img/QQ截图20210318164049.png","hash":"aa19a5114c571bd4e1d5b6e611b2dfe72f8956f6","modified":1616056852064},{"_id":"source/img/QQ截图20210318164346.png","hash":"88f2136bf61412fe1fc2150aefb6d8cbc7f29343","modified":1616057028570},{"_id":"source/img/QQ截图20210319085415.png","hash":"cec7f3fe30a9e0aaafc6af0f4fac772dc587fe3a","modified":1616115257387},{"_id":"source/img/QQ截图20210319090259.png","hash":"aed492e6c7d88e51e877d9baf332f75d7a033b5a","modified":1616115780927},{"_id":"source/img/QQ截图20210319091622.png","hash":"0a64a0491671344163191ada892f78798e20e55c","modified":1616116816189},{"_id":"source/img/20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png","hash":"01762dfa751127e3671f431d272980d7d0f1dac1","modified":1588434477756},{"_id":"source/img/20200811145254657.png","hash":"f4200a50cd76680d79086050953ee74df7ea5ba0","modified":1615973761548},{"_id":"source/head-img/head.png","hash":"397a91bbf08826302101f4e452706044a17cf801","modified":1616140301796},{"_id":"themes/next/.gitignore","hash":"bd3702bb6941eb6f2ed7454db69ecf8ac0cad400","modified":1614930497312},{"_id":"themes/next/LICENSE","hash":"0e12aed461110e809af1a52728f499f852e85e0a","modified":1614930497312},{"_id":"themes/next/README.md","hash":"1ce10bcf2b1f95f70b4afaee1cd847254a2cbe0a","modified":1614930497313},{"_id":"themes/next/_config.yml","hash":"cec570f92b84f1cea29a29b7446c7ed038416027","modified":1616460119005},{"_id":"themes/next/layout/archive.ejs","hash":"9d943ce1c2880419ae71294ac5c6c249936161c3","modified":1616383790310},{"_id":"themes/next/layout/category.ejs","hash":"c97be36b33bb44957778587f00c978f2d28016f8","modified":1614930497344},{"_id":"themes/next/layout/index.ejs","hash":"c97be36b33bb44957778587f00c978f2d28016f8","modified":1614930497344},{"_id":"themes/next/layout/layout.ejs","hash":"f4ce04d45a5100fcb2ee9145ca42c43424fced06","modified":1614930497345},{"_id":"themes/next/layout/page.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1614930497345},{"_id":"themes/next/layout/post.ejs","hash":"7d80e4e36b14d30a7cd2ac1f61376d9ebf264e8b","modified":1614930497346},{"_id":"themes/next/source/style.scss","hash":"4bb6c5ea3c90e02e8761b294b0240421ae19f30e","modified":1614930497360},{"_id":"themes/next/layout/tag.ejs","hash":"c97be36b33bb44957778587f00c978f2d28016f8","modified":1614930497346},{"_id":"themes/next/layout/_partial/archive.ejs","hash":"266833470af0fbf4c0816e79d94c52f4d7cec259","modified":1616392931675},{"_id":"themes/next/layout/_partial/article.ejs","hash":"0eae511e518bde9a35e45b026364306bbad46167","modified":1614930497320},{"_id":"themes/next/layout/_partial/footer.ejs","hash":"cf7451fd4b6a0be8e4d6f532f1c9759b8b5841ad","modified":1614930497321},{"_id":"themes/next/layout/_partial/google-analytics.ejs","hash":"1594e0688e0a1ce47c3b09bb0a56b9f70f8c8fc9","modified":1614930497321},{"_id":"themes/next/layout/_partial/head.ejs","hash":"e3df74ba8b872b08fb939f462e6708a4a7ae123e","modified":1614930497322},{"_id":"themes/next/layout/_partial/header.ejs","hash":"5d0d00edc298cf2b8530120d17fef7c162a42cb0","modified":1614930497322},{"_id":"themes/next/layout/_partial/loading.ejs","hash":"892d8639304b0dfb32229f8a6700530f6debdffb","modified":1614930497323},{"_id":"themes/next/layout/_partial/post.ejs","hash":"1ca60c075a019124c6d857485502f2b27aec783c","modified":1616393402805},{"_id":"themes/next/layout/_partial/sidebar.ejs","hash":"25073ecda4fd414f2761a5cfd96abfbb8239d9f2","modified":1614930497343},{"_id":"themes/next/source/fonts/icomoon.eot","hash":"09e365cb1dfa85a63d0841b69c30020cff621dad","modified":1614930497348},{"_id":"themes/next/layout/_partial/scripts.ejs","hash":"2783bd0a421f1735bcd7a38c0999a09736224287","modified":1614930497342},{"_id":"themes/next/source/fonts/icomoon.svg","hash":"0eac2502590339c38c69f254256cda80a32747c0","modified":1614930497348},{"_id":"themes/next/source/fonts/icomoon.woff","hash":"c58f59e279dcc265fb43a0d8378b92064c120ce8","modified":1614930497349},{"_id":"themes/next/source/img/algolia.svg","hash":"e822a2b6ebfa48e935abd2950209cc2891d35a17","modified":1614930497351},{"_id":"themes/next/source/img/azure.svg","hash":"d355a126d8d47647140022f32e755d41c5708474","modified":1614930497352},{"_id":"themes/next/source/img/baidu.svg","hash":"c8c111d40c97e0c662b0b12849702e7207feeee5","modified":1614930497353},{"_id":"themes/next/source/fonts/selection.json","hash":"63e57a0fdd6138c8872f8cafa24b951eaf9fd564","modified":1614930497350},{"_id":"themes/next/source/fonts/icomoon.ttf","hash":"db33ccce951a88b6a08f147363ace84d20db93ae","modified":1614930497349},{"_id":"themes/next/source/img/logo.png","hash":"9cd3926b2258a9ef3301a6ba5bd97b58f549bd8a","modified":1614930497354},{"_id":"themes/next/source/img/google.svg","hash":"8012105edafb46769b6d2228ab9eaa248290fea7","modified":1614930497353},{"_id":"themes/next/source/img/sidebar-bg.png","hash":"99613a8ec2c70e92692e740a439388439a2b3b2c","modified":1614930497356},{"_id":"themes/next/source/js/jquery.fitvids.js","hash":"498d2b1a5cfd53ce9b320c9ccd7d53ea7b04ffb7","modified":1614930497358},{"_id":"themes/next/source/js/app.js","hash":"07369b9ab203525d273efa500b215ef16b10e260","modified":1614930497357},{"_id":"themes/next/source/js/search.js","hash":"c863dec6e11a3908c8d0a5cff78e32eaf964f1b9","modified":1614930497360},{"_id":"themes/next/source/style/archive.scss","hash":"401a8a647929d70f13423207d6afcc1198a75182","modified":1614930497361},{"_id":"themes/next/source/style/base.scss","hash":"c5c7f2c54e09aa248fd6800b5072fb86fd847be5","modified":1614930497362},{"_id":"themes/next/source/style/button.scss","hash":"fd4f493fc2d0539cc12e0c6d7fa37e84912ff44e","modified":1614930497362},{"_id":"themes/next/source/style/content.scss","hash":"f66513e6b79bcc58fd791191bca14b1031509934","modified":1616128444446},{"_id":"themes/next/source/style/fonts.scss","hash":"7eac30a4e19ae259816ffc1754391b64e1b8b588","modified":1614930497363},{"_id":"themes/next/source/style/header.scss","hash":"538821fe627f20c08cab7acc9a31fc57c521df77","modified":1614930497365},{"_id":"themes/next/source/style/loading.scss","hash":"14e1a0b7a7501e968ba2c9022e767205f289b014","modified":1614930497365},{"_id":"themes/next/source/style/footer.scss","hash":"66b695c453e0acc9ba085f600a8789dddf7217fb","modified":1614930497364},{"_id":"themes/next/source/style/normalize.scss","hash":"f995dab1c91c02ba01562b39ca5f09996cfa6364","modified":1614930497366},{"_id":"themes/next/source/style/pagination.scss","hash":"236a24f5542cb1f1391a34600efaa43189a71b42","modified":1614930497367},{"_id":"themes/next/source/style/post.scss","hash":"66c3767e84ef3497039b7af52c40114b99bfdfb7","modified":1614930497367},{"_id":"themes/next/source/style/sidebar.scss","hash":"5522bd10606a3731091767ad64256165c5c22c19","modified":1614930497368},{"_id":"themes/next/source/style/search.scss","hash":"0fb876e8ee1cb97801f58efdd67cf052c454e960","modified":1614930497367},{"_id":"source/img/QQ截图20210318111958.png","hash":"b2f88c7f59423ab9f0c166958f63d87a92ccbec0","modified":1616047232389},{"_id":"themes/next/source/style/variables.scss","hash":"30ad4f9fe42eb9a03d3b170d90c4814781dfbe17","modified":1614930497369},{"_id":"themes/next/source/img/logo.psd","hash":"93fbddfccc3916cbae025bb215a996914b1b27ed","modified":1614930497355},{"_id":"themes/next/source/js/jquery.min.js","hash":"0c3192b500a4fd550e483cf77a49806a5872185b","modified":1614930497359},{"_id":"themes/next/source/img/avatar.png","hash":"397a91bbf08826302101f4e452706044a17cf801","modified":1616140301796},{"_id":"source/img/fdacab61d58425e368f30729feb2d2c8.jpg","hash":"e1474722d30b4fba4ff6ecb4a3acf58aef1fa1fa","modified":1559724922000},{"_id":"themes/next/demo/ghost-theme-memory-screenshot.jpg","hash":"a112ee6b71690c52f37572a5a6093582e69d95bf","modified":1614930497315},{"_id":"themes/next/demo/ghost-theme-memory-screenshot.png","hash":"d77251051f0d783c84294f8eaac26f7650930eee","modified":1614930497317},{"_id":"public/gunName/index.html","hash":"9d498a10e6ff257ad8e4811e3c13392e2f26b43e","modified":1616460128426},{"_id":"public/about/index.html","hash":"210fab962aa47b0787f7ae404eeaad3b88cb02bf","modified":1616460128426},{"_id":"public/header/index.html","hash":"999e75106bc89abf2b7e57ddadef3e033959adf9","modified":1616460128426},{"_id":"public/2021/03/12/排序函数/index.html","hash":"94867887b8651b616a88349949b9eb75d7217b47","modified":1616460128426},{"_id":"public/2021/03/08/wHo-i-M-I/index.html","hash":"2b6e2fddc23cdd4e8b1df73957b0d35d4a074110","modified":1616460128426},{"_id":"public/2021/03/05/hello-world/index.html","hash":"f3b0151e944ca1c95d9f9ce8343045562d207cad","modified":1616460128426},{"_id":"public/archives/index.html","hash":"dd8556c0f75e4408f440c4abf4fe36ded9ce2eb1","modified":1616461235504},{"_id":"public/2021/03/17/SAP-Data-Services-Designer/index.html","hash":"0ae7c8e37384396b9b671cc7145c3b6cac42d298","modified":1616460128426},{"_id":"public/2021/03/15/开窗函数/index.html","hash":"5dd29323fa17696afe88d66ac67d5ad8adfb62b4","modified":1616460128426},{"_id":"public/archives/2021/index.html","hash":"2a77630f7d92cf4dc0492f9c68ad3092b1fe45d1","modified":1616461235504},{"_id":"public/tags/life/index.html","hash":"88ac33ae92e8f6b9e69186c95351d60fe1b71a3b","modified":1616460128426},{"_id":"public/archives/2021/03/index.html","hash":"cbd26fe3d16baef82221a57f5786c2b8a7d6bf9e","modified":1616461235504},{"_id":"public/tags/study/index.html","hash":"f1aecc9ee1be571286433cec98b4132e558b1f82","modified":1616461235504},{"_id":"public/index.html","hash":"15626c9b0bb914cfb239ceea6e89610166389119","modified":1616461235504},{"_id":"public/img/202005241421367251716257711.500x0.jpg.webp","hash":"dffaab9b1a7261004410113b1ad2d25083822cb2","modified":1616383094289},{"_id":"public/img/QQ截图20210312145034.png","hash":"0ca287359c91fcd962de1d93dd4c14269341b443","modified":1616383094289},{"_id":"public/img/QQ截图20210312144133.png","hash":"227e9d2932081e42228d2c19baae6df10c29646d","modified":1616383094289},{"_id":"public/img/20200811154704891.png","hash":"98f52bacf840757f2196c69682e72ca89f9d65a3","modified":1616383094289},{"_id":"public/img/QQ截图20210312145927.png","hash":"7d7fcfff4048ff873aa703e7356df6f6569c8275","modified":1616383094289},{"_id":"public/img/QQ截图20210312150624.png","hash":"00e2c5aef947fa9afa1b16aae70a384b8e67ba15","modified":1616383094289},{"_id":"public/img/QQ截图20210312160137.png","hash":"7bd34c97762e4fcf64c41e1c3aa8b02f46be464b","modified":1616383094289},{"_id":"public/img/QQ截图20210315093653.png","hash":"d926c3a8966a02e34a29370418ab430b078d1154","modified":1616383094289},{"_id":"public/img/QQ截图20210315100337.png","hash":"0d432c77ccd669cfa354ed9c4d64ba6e4e76740b","modified":1616383094289},{"_id":"public/img/QQ截图20210315135813.png","hash":"133b52dc15f610632d09a0b3ccd59148b2866e1a","modified":1616383094289},{"_id":"public/img/QQ截图20210315150441.png","hash":"eb3e413c579a75a5064be3f8ca6d2347c94f12bf","modified":1616383094289},{"_id":"public/img/QQ截图20210318164227.png","hash":"0efffdbee9e25c2a82800250e303237c4c545383","modified":1616383094289},{"_id":"public/img/QQ截图20210318170041.png","hash":"48f149911d1e13a38a91e7c79fb286c9b7df127c","modified":1616383094289},{"_id":"public/img/QQ截图20210318170601.png","hash":"a8a971679c7f2fd77be98c4c6fb78242c99d2bb8","modified":1616383094289},{"_id":"public/img/QQ截图20210318170649.png","hash":"40f48dd21577d31cd6919fb2cd9b194c58d27a04","modified":1616383094289},{"_id":"public/img/QQ截图20210318171011.png","hash":"593c99385b1ec73f1dcfce273d904d3a580b0e1f","modified":1616383094289},{"_id":"public/img/QQ截图20210319085849.png","hash":"3e417272edd2df31694362e95818e88a7795d472","modified":1616383094289},{"_id":"public/img/QQ截图20210319090825.png","hash":"3e10c20f30112c3706c9fa430f6e1dbf8bb22d76","modified":1616383094289},{"_id":"public/img/QQ截图20210319091413.png","hash":"86c59ab9f13ff18809043efa0e46416f92ccd01f","modified":1616383094289},{"_id":"public/img/QQ截图20210319090340.png","hash":"7e8c4aab5eef58113a888afd26d92a11dafef181","modified":1616383094289},{"_id":"public/img/QQ截图20210319092829.png","hash":"fe8ac76dbdecdd4affca545e3ae810ee62779612","modified":1616383094289},{"_id":"public/img/QQ截图20210319093220.png","hash":"b275dd310e7a1b41a979c998242c64e7dbb392be","modified":1616383094289},{"_id":"public/img/QQ截图20210319094058.png","hash":"f0cf28969ad3cfaff34837d08396e310f3620aaf","modified":1616383094289},{"_id":"public/img/QQ截图20210319094206.png","hash":"d81efe3c1f93446e35647b52e0e445e4ab13f049","modified":1616383094289},{"_id":"public/fonts/icomoon.eot","hash":"09e365cb1dfa85a63d0841b69c30020cff621dad","modified":1616383094289},{"_id":"public/fonts/icomoon.svg","hash":"0eac2502590339c38c69f254256cda80a32747c0","modified":1616383094289},{"_id":"public/img/algolia.svg","hash":"e822a2b6ebfa48e935abd2950209cc2891d35a17","modified":1616383094289},{"_id":"public/fonts/icomoon.ttf","hash":"db33ccce951a88b6a08f147363ace84d20db93ae","modified":1616383094289},{"_id":"public/fonts/icomoon.woff","hash":"c58f59e279dcc265fb43a0d8378b92064c120ce8","modified":1616383094289},{"_id":"public/img/azure.svg","hash":"d355a126d8d47647140022f32e755d41c5708474","modified":1616383094289},{"_id":"public/img/baidu.svg","hash":"c8c111d40c97e0c662b0b12849702e7207feeee5","modified":1616383094289},{"_id":"public/img/logo.png","hash":"9cd3926b2258a9ef3301a6ba5bd97b58f549bd8a","modified":1616383094289},{"_id":"public/img/sidebar-bg.png","hash":"99613a8ec2c70e92692e740a439388439a2b3b2c","modified":1616383094289},{"_id":"public/img/google.svg","hash":"8012105edafb46769b6d2228ab9eaa248290fea7","modified":1616383094289},{"_id":"public/head-img/QQ图片20210320214654.png","hash":"4acb5505d8fe648175b103c1fba0a6273e91f1fc","modified":1616383094289},{"_id":"public/img/20200811154500211.png","hash":"20d71313d6bee59c0a1921984a2732f99eb4b672","modified":1616383094289},{"_id":"public/img/QQ截图20210317173744.png","hash":"0b5ed152bce8c3f77552f3e81f7b8d99dda16fe6","modified":1616383094289},{"_id":"public/img/QQ截图20210318164049.png","hash":"aa19a5114c571bd4e1d5b6e611b2dfe72f8956f6","modified":1616383094289},{"_id":"public/img/QQ截图20210318164346.png","hash":"88f2136bf61412fe1fc2150aefb6d8cbc7f29343","modified":1616383094289},{"_id":"public/img/QQ截图20210319085415.png","hash":"cec7f3fe30a9e0aaafc6af0f4fac772dc587fe3a","modified":1616383094289},{"_id":"public/img/QQ截图20210319090259.png","hash":"aed492e6c7d88e51e877d9baf332f75d7a033b5a","modified":1616383094289},{"_id":"public/img/QQ截图20210319091622.png","hash":"0a64a0491671344163191ada892f78798e20e55c","modified":1616383094289},{"_id":"public/img/QQ截图20210319093607.png","hash":"51acf6a61c0717cd25582b98b121fc3bffcb42ca","modified":1616383094289},{"_id":"public/img/QQ截图20210319093541.png","hash":"1d311c59adc7eca430bbc490d78002dd3beaf04f","modified":1616383094289},{"_id":"public/img/logo.psd","hash":"93fbddfccc3916cbae025bb215a996914b1b27ed","modified":1616383094289},{"_id":"public/head-img/head.png","hash":"397a91bbf08826302101f4e452706044a17cf801","modified":1616383094289},{"_id":"public/img/20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png","hash":"01762dfa751127e3671f431d272980d7d0f1dac1","modified":1616383094289},{"_id":"public/img/20200811145254657.png","hash":"f4200a50cd76680d79086050953ee74df7ea5ba0","modified":1616383094289},{"_id":"public/js/app.js","hash":"df35f95bc764610b2ff5081c2ad597d4480ab78e","modified":1616383094289},{"_id":"public/js/jquery.fitvids.js","hash":"57946a22c79654014eb00fb548f727d302221873","modified":1616383094289},{"_id":"public/js/search.js","hash":"c863dec6e11a3908c8d0a5cff78e32eaf964f1b9","modified":1616383094289},{"_id":"public/img/avatar.png","hash":"397a91bbf08826302101f4e452706044a17cf801","modified":1616383094289},{"_id":"public/fonts/selection.json","hash":"c38f13105ee7c35a67476dd80eaa2ffd037c124b","modified":1616383094289},{"_id":"public/style/archive.css","hash":"8e07f16eb5eacaa1ee750e8c30db617676c2ccb1","modified":1616383094289},{"_id":"public/style/button.css","hash":"d37e2a35f8f88d453db8c2430e18d689b32c348f","modified":1616383094289},{"_id":"public/style/base.css","hash":"5d4b42859fddcc821b74addca3ea4fcc54fecd85","modified":1616383094289},{"_id":"public/style/fonts.css","hash":"f073390685554dac33f49170f75da6ee1ac2c568","modified":1616383094289},{"_id":"public/style/loading.css","hash":"5ce5b1f8a42f6efa9a2189f0ef437d17501f6d88","modified":1616383094289},{"_id":"public/style/header.css","hash":"6344afe0e33e8f4e352e0ee479ffa65654f80b1a","modified":1616383094289},{"_id":"public/style/content.css","hash":"f962325068a182967af87115f202934ae17708c3","modified":1616383094289},{"_id":"public/style/normalize.css","hash":"3e9a36930c221013d320c4a06df99f69c4a4440d","modified":1616383094289},{"_id":"public/style/footer.css","hash":"3ba591f936405af6c0ebfcb7ce7ee962524b761f","modified":1616383094289},{"_id":"public/style/pagination.css","hash":"d1e2f048c36d9458196bee01b10d4a8ba0b291a1","modified":1616383094289},{"_id":"public/style/post.css","hash":"972a87b06cd45ca6ee67f71ac91a09b10bc9c5e5","modified":1616383094289},{"_id":"public/style/variables.css","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1616383094289},{"_id":"public/style/search.css","hash":"6d09ffe2a5ee710e4c51ff9953ec72b8f0a97a73","modified":1616383094289},{"_id":"public/style/sidebar.css","hash":"2d038fbdee00da03f809d2ab4f0312bdb1028d3c","modified":1616383094289},{"_id":"public/img/QQ截图20210318111958.png","hash":"b2f88c7f59423ab9f0c166958f63d87a92ccbec0","modified":1616383094289},{"_id":"public/js/jquery.min.js","hash":"0dc32db4aa9c5f03f3b38c47d883dbd4fed13aae","modified":1616383094289},{"_id":"public/img/fdacab61d58425e368f30729feb2d2c8.jpg","hash":"e1474722d30b4fba4ff6ecb4a3acf58aef1fa1fa","modified":1616383094289},{"_id":"public/style.css","hash":"35516c8a4c67e47ad3201fa21ac4e387d88bc418","modified":1616383094289},{"_id":"source/_posts/蛋.md","hash":"85b3c75fbeed93a600b29de9dc8fb922b9367cf9","modified":1616392524991},{"_id":"public/2021/03/22/蛋/index.html","hash":"8ba8c8e8eaf63a462edf49bb0ef27e96e3153d18","modified":1616460128426},{"_id":"source/_posts/python爬虫-爬取steam统计数据（steam游戏在线人数）（一）.md","hash":"ab851f015fa9dd18059ebcfe393d6e3c27466fa1","modified":1616460595406},{"_id":"public/2021/03/22/python爬虫-爬取steam统计数据（steam游戏在线人数）（一）/index.html","hash":"e62878431eccdd529333f8be57ea8671d7ba567c","modified":1616461235504},{"_id":"public/tags/sql/index.html","hash":"37a8fc76f07f9a5e48ff497183da49b9b79fb9db","modified":1616460128426},{"_id":"public/tags/python/index.html","hash":"347c1b0e15de998165fed865347e18bc864e7e4c","modified":1616461235504},{"_id":"public/tags/ds/index.html","hash":"6bb9e05c9e10342f8c1a8a0abf6c4445b135699d","modified":1616460128426},{"_id":"source/img/QQ截图20210322163703.png","hash":"70a7b70810cb2113f6b88acc75b73f32b4012fd9","modified":1616402226625},{"_id":"source/img/QQ截图20210322162407.png","hash":"8ef42b2932cf86dab0c484c659fff8784375ff5f","modified":1616401448477},{"_id":"source/img/QQ截图20210322162126.png","hash":"55a5db9f58a837fc5e3ea86de330680e8f14af87","modified":1616401289969},{"_id":"source/img/QQ截图20210322162801.png","hash":"8d306c393b3abe3c7da267251c391d51a8fbd373","modified":1616401683527},{"_id":"source/img/QQ截图20210322165150.png","hash":"2bb87d156bc635ada7dfce533558fcecd2ca630e","modified":1616403111525},{"_id":"source/img/53186325_p0.jpg","hash":"d658283eadbb562c122884c16ad9756532215ade","modified":1599306146317},{"_id":"source/img/bbe600fa828ba61e7b3276565634970a314e593a.gif","hash":"d269afc1332e298e6e02d515d8c1b505891c0197","modified":1616339514000},{"_id":"source/img/2a77752309f790520f2b21421bf3d7ca7acbd5ed.gif","hash":"ee2ce18c9e2ee41bcdf93e936788d51c72fb8315","modified":1616339600000},{"_id":"source/img/7a1c08c79f3df8dccd0ae9edda11728b461028ed.gif","hash":"fa096f5c069e4eb735dbbf8dfe3de7c0e0230600","modified":1616339588000},{"_id":"public/img/QQ截图20210322163703.png","hash":"70a7b70810cb2113f6b88acc75b73f32b4012fd9","modified":1616404499192},{"_id":"public/img/QQ截图20210322162407.png","hash":"8ef42b2932cf86dab0c484c659fff8784375ff5f","modified":1616404499192},{"_id":"public/img/QQ截图20210322162126.png","hash":"55a5db9f58a837fc5e3ea86de330680e8f14af87","modified":1616404499192},{"_id":"public/img/QQ截图20210322162801.png","hash":"8d306c393b3abe3c7da267251c391d51a8fbd373","modified":1616404499192},{"_id":"public/img/QQ截图20210322165150.png","hash":"2bb87d156bc635ada7dfce533558fcecd2ca630e","modified":1616404499192},{"_id":"public/img/53186325_p0.jpg","hash":"d658283eadbb562c122884c16ad9756532215ade","modified":1616404499192},{"_id":"public/img/bbe600fa828ba61e7b3276565634970a314e593a.gif","hash":"d269afc1332e298e6e02d515d8c1b505891c0197","modified":1616404499192},{"_id":"public/img/2a77752309f790520f2b21421bf3d7ca7acbd5ed.gif","hash":"ee2ce18c9e2ee41bcdf93e936788d51c72fb8315","modified":1616404499192},{"_id":"public/img/7a1c08c79f3df8dccd0ae9edda11728b461028ed.gif","hash":"fa096f5c069e4eb735dbbf8dfe3de7c0e0230600","modified":1616404499192},{"_id":"source/Links/index.md","hash":"5f0f41abbf790f7a2672629790ba56769944be41","modified":1616464333345},{"_id":"public/Links/index.html","hash":"a2ed93b362777a2134d7dbfec93018f6e3094b90","modified":1616467303957},{"_id":"source/img/show.png","hash":"6d57c0eb831431aa3ccf7b2d8d06b439d9b78545","modified":1616460920674},{"_id":"public/img/show.png","hash":"6d57c0eb831431aa3ccf7b2d8d06b439d9b78545","modified":1616461235504}],"Category":[],"Data":[],"Page":[{"title":"黑色魅影","date":"2021-03-20T18:22:33.000Z","_content":"\n# 你是首选，也是唯一。\n\n# 玫瑰纵易名，芳香依如故。\n\n# 我扣动扳机，他们开始跳舞。\n\n# 比花花解语，比玉玉生香。\n\n# 醉后不知天在水，满床清梦压梦河。","source":"gunName/index.md","raw":"---\ntitle: 黑色魅影\ndate: 2021-03-21 02:22:33\n---\n\n# 你是首选，也是唯一。\n\n# 玫瑰纵易名，芳香依如故。\n\n# 我扣动扳机，他们开始跳舞。\n\n# 比花花解语，比玉玉生香。\n\n# 醉后不知天在水，满床清梦压梦河。","updated":"2021-03-22T07:12:35.386Z","path":"gunName/index.html","_id":"ckmk0reyq0000ekvsf38qgiwi","comments":1,"layout":"page","content":"<h1><span id=\"你是首选也是唯一\">你是首选，也是唯一。</span></h1><h1><span id=\"玫瑰纵易名芳香依如故\">玫瑰纵易名，芳香依如故。</span></h1><h1><span id=\"我扣动扳机他们开始跳舞\">我扣动扳机，他们开始跳舞。</span></h1><h1><span id=\"比花花解语比玉玉生香\">比花花解语，比玉玉生香。</span></h1><h1><span id=\"醉后不知天在水满床清梦压梦河\">醉后不知天在水，满床清梦压梦河。</span></h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"你是首选，也是唯一。\"><a href=\"#你是首选，也是唯一。\" class=\"headerlink\" title=\"你是首选，也是唯一。\"></a>你是首选，也是唯一。</h1><h1 id=\"玫瑰纵易名，芳香依如故。\"><a href=\"#玫瑰纵易名，芳香依如故。\" class=\"headerlink\" title=\"玫瑰纵易名，芳香依如故。\"></a>玫瑰纵易名，芳香依如故。</h1><h1 id=\"我扣动扳机，他们开始跳舞。\"><a href=\"#我扣动扳机，他们开始跳舞。\" class=\"headerlink\" title=\"我扣动扳机，他们开始跳舞。\"></a>我扣动扳机，他们开始跳舞。</h1><h1 id=\"比花花解语，比玉玉生香。\"><a href=\"#比花花解语，比玉玉生香。\" class=\"headerlink\" title=\"比花花解语，比玉玉生香。\"></a>比花花解语，比玉玉生香。</h1><h1 id=\"醉后不知天在水，满床清梦压梦河。\"><a href=\"#醉后不知天在水，满床清梦压梦河。\" class=\"headerlink\" title=\"醉后不知天在水，满床清梦压梦河。\"></a>醉后不知天在水，满床清梦压梦河。</h1>"},{"title":"俺様だ❕","date":"2021-03-19T07:01:22.000Z","_content":"\nnothing to me","source":"about/index.md","raw":"---\ntitle: 俺様だ❕\ndate: 2021-03-19 15:01:22\n---\n\nnothing to me","updated":"2021-03-22T07:11:29.223Z","path":"about/index.html","_id":"ckmk0reyw0002ekvsfauvcyop","comments":1,"layout":"page","content":"<p>nothing to me</p>\n","site":{"data":{}},"excerpt":"","more":"<p>nothing to me</p>\n"},{"title":"俺の頭","date":"2021-03-20T18:08:52.000Z","_content":"\n<img src=\"\\head-img\\head.png\" alt=\"head\" style=\"zoom:100%;\" />\n\n<img src=\"\\head-img\\QQ图片20210320214654.png\" alt=\"head\" style=\"zoom:100%;\" />\n\n","source":"header/index.md","raw":"---\ntitle: 俺の頭\ndate: 2021-03-21 02:08:52\n---\n\n<img src=\"\\head-img\\head.png\" alt=\"head\" style=\"zoom:100%;\" />\n\n<img src=\"\\head-img\\QQ图片20210320214654.png\" alt=\"head\" style=\"zoom:100%;\" />\n\n","updated":"2021-03-22T07:12:53.885Z","path":"header/index.html","_id":"ckmk0reyx0003ekvs2r0n0qqj","comments":1,"layout":"page","content":"<img src=\"\\head-img\\head.png\" alt=\"head\" style=\"zoom:100%;\">\n\n<img src=\"\\head-img\\QQ图片20210320214654.png\" alt=\"head\" style=\"zoom:100%;\">\n\n","site":{"data":{}},"excerpt":"","more":"<img src=\"\\head-img\\head.png\" alt=\"head\" style=\"zoom:100%;\" />\n\n<img src=\"\\head-img\\QQ图片20210320214654.png\" alt=\"head\" style=\"zoom:100%;\" />\n\n"},{"title":"Links","date":"2021-03-23T00:36:44.000Z","_content":"\n### 本丸\n\n- [freere-aoki](https://freere-aoki.github.io/)\n\n### 友人帐\n\n<img class=\"litimg\" src=\"https://adilphoto-1302748124.cos.ap-beijing.myqcloud.com/2021-03-19-adills.jpg\" style=\"zoom:100%;\" />\n\n- [Adil](https://adil.com.cn/) —— 生命不死，折腾不止\n\n\n\n\n\n\n\n```css\nname: Freere-Aoki\nlink: https://freere-aoki.github.io/\navatar: https://freere-aoki.github.io/img/avatar.png\ndescr: 醉后不知天在水，满床清梦压梦河。\nsiteshot: https://freere-aoki.github.io/img/show.png\n```\n\n","source":"Links/index.md","raw":"title: Links\ndate: 2021-03-23 08:36:44\n\n---\n\n### 本丸\n\n- [freere-aoki](https://freere-aoki.github.io/)\n\n### 友人帐\n\n<img class=\"litimg\" src=\"https://adilphoto-1302748124.cos.ap-beijing.myqcloud.com/2021-03-19-adills.jpg\" style=\"zoom:100%;\" />\n\n- [Adil](https://adil.com.cn/) —— 生命不死，折腾不止\n\n\n\n\n\n\n\n```css\nname: Freere-Aoki\nlink: https://freere-aoki.github.io/\navatar: https://freere-aoki.github.io/img/avatar.png\ndescr: 醉后不知天在水，满床清梦压梦河。\nsiteshot: https://freere-aoki.github.io/img/show.png\n```\n\n","updated":"2021-03-23T01:52:13.345Z","path":"Links/index.html","_id":"ckmlakm110000eovsgvxn8n5q","comments":1,"layout":"page","content":"<h3><span id=\"本丸\">本丸</span></h3><ul>\n<li><a href=\"https://freere-aoki.github.io/\">freere-aoki</a></li>\n</ul>\n<h3><span id=\"友人帐\">友人帐</span></h3><img class=\"litimg\" src=\"https://adilphoto-1302748124.cos.ap-beijing.myqcloud.com/2021-03-19-adills.jpg\" style=\"zoom:100%;\">\n\n<ul>\n<li><a href=\"https://adil.com.cn/\">Adil</a> —— 生命不死，折腾不止</li>\n</ul>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name: Freere-Aoki</span><br><span class=\"line\">link: https://freere-aoki.github.io/</span><br><span class=\"line\">avatar: https://freere-aoki.github.io/img/avatar.png</span><br><span class=\"line\">descr: 醉后不知天在水，满床清梦压梦河。</span><br><span class=\"line\">siteshot: https://freere-aoki.github.io/img/show.png</span><br></pre></td></tr></table></figure>\n\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"本丸\"><a href=\"#本丸\" class=\"headerlink\" title=\"本丸\"></a>本丸</h3><ul>\n<li><a href=\"https://freere-aoki.github.io/\">freere-aoki</a></li>\n</ul>\n<h3 id=\"友人帐\"><a href=\"#友人帐\" class=\"headerlink\" title=\"友人帐\"></a>友人帐</h3><img class=\"litimg\" src=\"https://adilphoto-1302748124.cos.ap-beijing.myqcloud.com/2021-03-19-adills.jpg\" style=\"zoom:100%;\" />\n\n<ul>\n<li><a href=\"https://adil.com.cn/\">Adil</a> —— 生命不死，折腾不止</li>\n</ul>\n<figure class=\"highlight css\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">name: Freere-Aoki</span><br><span class=\"line\">link: https://freere-aoki.github.io/</span><br><span class=\"line\">avatar: https://freere-aoki.github.io/img/avatar.png</span><br><span class=\"line\">descr: 醉后不知天在水，满床清梦压梦河。</span><br><span class=\"line\">siteshot: https://freere-aoki.github.io/img/show.png</span><br></pre></td></tr></table></figure>\n\n"}],"Post":[{"title":"SAP Data Services Designer","date":"2021-03-17T01:12:54.000Z","_content":"\n##### SAP DATA SERVICES DESIGNER工具介绍和基础使用（抽表）\n\n接下来简称DS\n\nSAP BusinessObjects Data Service 是通过SAP HANA认证的ETL工具。采用数据批量处理的方式，定期执行后台作业，将数据从多个业务系统中抽取出来，并进行必要的处理（转换，合并，过滤，清晰），然后在加载到HANA数据库中。\n\nDS组件之间的关系：\n\n<img src=\"\\img\\20200811145254657.png\" alt=\"20200811145254657\" style=\"zoom:60%;\" />\n\n| Designer      | 用户可在此界面1. 创建、测试以及执行填充数据仓库的作业<br/>2. 创建并通过拖拽的方法连接对象形成流程图<br/>3. 在流程图中打开编辑修改对象的配置<br/>4. 定义数据映像、转换以及逻辑控制<br/>5. 通过将对象组合到工作流（作业执行定义）和数据流（数据转换定义）中来创建应用程序 |\n| :------------ | ------------------------------------------------------------ |\n| Job Server    | 启动数据服务处理的引擎以及数据服务套件与其他组件的接口的引擎的应用程序。 |\n| Engine        | 执行在Designer中定义的各个作业，以有效地完成已定义的任务。   |\n| Repository    | 存储Designer预定义系统对象和用户定义对象（包括源和目标元数据以及转换规则）的数据库。 创建一个本地存储库，然后创建一个中央存储库，以与其他用户共享对象并进行版本控制。 |\n| Access Server | 在Web应用程序与数据服务作业服务器和引擎之间传递消息。 提供用于请求响应处理的可靠且可扩展的接口。 |\n| Administrator | 提供以下基于浏览器的数据服务资源管理的Web管理员：<br/>1. 计划，监视和执行批处理作业<br/>2. 配置，启动和停止实时服务<br/>3. 配置作业服务器，访问服务器和存储库使用情况<br/>4. 配置和管理适配器<br/>5. 管理用户<br/>6. 通过Web服务发布批处理作业和实时服务 |\n\n###### 用户界面介绍\n\n<img class=\"bigimg\" src=\"\\img\\QQ截图20210318111958.png\" alt=\"QQ截图20210318111958\" style=\"zoom:150%;\" />\n\nProjects(项目)：项目包含作业，工作流和数据流等子对象，项目是Data Services的最高级对象，主要用于组织管理子对象，一个项目通常包含多个作业\n\nJob(作业)：可独立安排执行的最小工作单元。 作业由工作流和数据流组成，这些工作流和数据流按顺序和指定方式处理流程。\n\nWork flows(工作流)：工作流指定处理数据流的顺序。将下级数据流安排在工作流下，以便一个数据流的输出准备好输入到预期数据流。\n\nData flows(数据流)：数据流是将源数据转换为目标数据的过程。数据流按在工作流中排列的顺序处理数据。数据流定义了数据服务需要完成的基本任务。 基本任务是将数据从一个或多个源移动到一个或多个目标表或文件。通过标识提取数据的源，数据应进行的转换以及目标来定义数据流。\n\n######   Data Services对象列表\n\n<img src=\"\\img\\20200811154500211.png\" alt=\"20200811154500211\" style=\"zoom:70%;\" />\n\n######   对象层级以及从属关系\n\n<img src=\"\\img\\20200811154704891.png\" alt=\"20200811154704891\" style=\"zoom:100%;\" />\n\n##### DS数据加载方式\n\n将演示最基本的从其他系统中抽取数据到SAP HANA中（多图预警）\n\n*注：~~如何创建datastores连接其他系统和数据库此文不进行阐述~~*，下面的演示为全量抽取，将一次将表中的全部数据抽取到你想要的数据库里。\n\n根据对象层级以及从属关系来创建\n\n*也可以直接在local object library点击不同的对象独立创建~~（但不推荐，因为不好管理也不好找）~~*\n\n首先创建project，在local object library界面中选择project，然后空白处选择New\n\n<img src=\"\\img\\QQ截图20210318164049.png\" alt=\"QQ截图20210318164049\" style=\"zoom:50%;\" />\n\n起一个你喜欢的名字（project name）*~~见名知意，最好再加上注释🙏~~*，然后点击create（创建）\n\n<img src=\"\\img\\QQ截图20210318164227.png\" alt=\"QQ截图20210318164227\" style=\"zoom:50%;\" />\n\n之后再local object library中右击刚刚创建的project，点击open（打开）\n\n<img src=\"\\img\\QQ截图20210318164346.png\" alt=\"QQ截图20210318164346\" style=\"zoom:50%;\" />\n\n它就会在project Area上显示树状图\n\n<img src=\"\\img\\QQ截图20210318170041.png\" alt=\"QQ截图20210318170041\" style=\"zoom:50%;\" />\n\n之后右击空白位置或者project选择new batch job（新建批量作业）\n\n<img src=\"\\img\\QQ截图20210318170601.png\" alt=\"QQ截图20210318170601\" style=\"zoom:50%;\" />\n\n通常名字和要进行的业务相关 ~~见名知意~~（这就是我们需要执行的作业，可以手动或者定时执行\n\n<img src=\"\\img\\QQ截图20210318170649.png\" alt=\"QQ截图20210318170649\" style=\"zoom:50%;\" />\n\n之后双击就应该会在右侧工作区打开，应该是一片空白，空无一物，这时我们就需要点击右侧工具区的Dataflow（数据流），然后到空白区域左键单击新建一个df，名字一般应和你要抽取的表同名，比如说：DF_XXXX\n\n<img src=\"\\img\\QQ截图20210318171011.png\" alt=\"QQ截图20210318171011\" style=\"zoom:50%;\" />\n\n之后鼠标双击你刚才新建的df进入df的工作区，准备开始抽取表数据\n\n###### 流程：\n\n1. 在你要抽取数据的datastore中右键tables—import by name创建source表（源数据表，也就是你要抽取的表）。\n2. 鼠标左键拖拽到df工作区，选择Make Source(作为源表)  。\n3. 然后在右侧工具区拖拽query对数据进行处理（~~也可以跳过query，不进行输入处理，直接将源表和目标表连线~~\n4. 从右侧工具区拖拽template(临时表)到df工具区，填上你想要抽到哪个datastore和schema。\n5. 保存执行\n\n###### 示例：\n\n步骤一：\n\n在datastore导入表\n\n<img src=\"\\img\\QQ截图20210319085415.png\" alt=\"QQ截图20210319085415\" style=\"zoom:50%;\" />\n\n填写表的信息，之后点击import导入\n\n<img src=\"\\img\\QQ截图20210319085849.png\" alt=\"QQ截图20210319085849\" style=\"zoom:50%;\" />\n\n步骤二：\n\n鼠标拖拽刚刚导入的表到右侧ds工作区，选择make source作为源表\n\n<img src=\"\\img\\QQ截图20210319090259.png\" alt=\"QQ截图20210319090259\" style=\"zoom:50%;\" />\n\n最后是这个样子的，中间图示的表格深蓝色而且清晰，绿色箭头向右\n\n<img src=\"\\img\\QQ截图20210319090340.png\" alt=\"QQ截图20210319090340\" style=\"zoom:50%;\" />\n\n步骤三：\n\n点击工具区中的query，鼠标图标应该会发生改变，随后点击df的工作区创建一个query\n\n<img src=\"\\img\\QQ截图20210319090825.png\" alt=\"QQ截图20210319090825\" style=\"zoom:50%;\" />\n\n之后通过鼠标悬浮到源表右侧的小点，鼠标图标应该会变换成一个拿着粉笔的手，随后左键单击拖拽就应该会出现连线，将线连接到query控件左侧的三角形\n\n<img src=\"\\img\\QQ截图20210319091413.png\" alt=\"QQ截图20210319091413\" style=\"zoom:50%;\" />\n\n随后双击进入query，对数据进行处理\n\n<img src=\"\\img\\QQ截图20210319091622.png\" alt=\"QQ截图20210319091622\" style=\"zoom: 50%;\" />\n\n步骤四：\n\n也是通过左键工具区中的template（临时表）到ds工作区，填写要抽到库里的表名和schema，表名应和要抽取的表同名\n\n<img src=\"\\img\\QQ截图20210319092829.png\" alt=\"QQ截图20210319092829\" style=\"zoom: 50%;\" />\n\n随后通过query连线到临时表，最后应该是这样子的\n\n<img src=\"\\img\\QQ截图20210319093220.png\" alt=\"QQ截图20210319093220\" style=\"zoom:50%;\" />\n\n双击右侧的临时表，点击options，拖到最下方吧这一行改为YES！~~不然字符串的数据抽取可能出现问题~~\n\n<img src=\"\\img\\QQ截图20210319093541.png\" alt=\"QQ截图20210319093541\" style=\"zoom:33%;\" />\n\n<img src=\"\\img\\QQ截图20210319093607.png\" alt=\"QQ截图20210319093607\" style=\"zoom:50%;\" />\n\n步骤五：\n\n到job页面或者在左侧project area右键job选运行。如果没保存会提示让你保存，随后执行，点ok\n\n<img src=\"\\img\\QQ截图20210319094058.png\" alt=\"QQ截图20210319094058\" style=\"zoom:50%;\" />\n\n<img src=\"\\img\\QQ截图20210319094206.png\" alt=\"QQ截图20210319094206\" style=\"zoom:50%;\" />\n\n保存执行！\n\n本文中展示数据皆为示例，不太具有实际参考价值，但步骤相同，推荐举一反三。\n\n[部分引自SAP Data Services Designer - Ⅰ（User interface and Setting）](https://blog.csdn.net/JanoZhuo/article/details/107934029)\n\n<img class=\"litimg\" src=\"\\img\\fdacab61d58425e368f30729feb2d2c8.jpg\" alt=\"fdacab61d58425e368f30729feb2d2c8\" style=\"zoom:50%;\" />\n\nこの何もないの世界に、お前わ何が欲しいのが\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","source":"_posts/SAP-Data-Services-Designer.md","raw":"---\ntitle: SAP Data Services Designer\ndate: 2021-03-17 09:12:54\ntags:\n  - study\n  - ds\n---\n\n##### SAP DATA SERVICES DESIGNER工具介绍和基础使用（抽表）\n\n接下来简称DS\n\nSAP BusinessObjects Data Service 是通过SAP HANA认证的ETL工具。采用数据批量处理的方式，定期执行后台作业，将数据从多个业务系统中抽取出来，并进行必要的处理（转换，合并，过滤，清晰），然后在加载到HANA数据库中。\n\nDS组件之间的关系：\n\n<img src=\"\\img\\20200811145254657.png\" alt=\"20200811145254657\" style=\"zoom:60%;\" />\n\n| Designer      | 用户可在此界面1. 创建、测试以及执行填充数据仓库的作业<br/>2. 创建并通过拖拽的方法连接对象形成流程图<br/>3. 在流程图中打开编辑修改对象的配置<br/>4. 定义数据映像、转换以及逻辑控制<br/>5. 通过将对象组合到工作流（作业执行定义）和数据流（数据转换定义）中来创建应用程序 |\n| :------------ | ------------------------------------------------------------ |\n| Job Server    | 启动数据服务处理的引擎以及数据服务套件与其他组件的接口的引擎的应用程序。 |\n| Engine        | 执行在Designer中定义的各个作业，以有效地完成已定义的任务。   |\n| Repository    | 存储Designer预定义系统对象和用户定义对象（包括源和目标元数据以及转换规则）的数据库。 创建一个本地存储库，然后创建一个中央存储库，以与其他用户共享对象并进行版本控制。 |\n| Access Server | 在Web应用程序与数据服务作业服务器和引擎之间传递消息。 提供用于请求响应处理的可靠且可扩展的接口。 |\n| Administrator | 提供以下基于浏览器的数据服务资源管理的Web管理员：<br/>1. 计划，监视和执行批处理作业<br/>2. 配置，启动和停止实时服务<br/>3. 配置作业服务器，访问服务器和存储库使用情况<br/>4. 配置和管理适配器<br/>5. 管理用户<br/>6. 通过Web服务发布批处理作业和实时服务 |\n\n###### 用户界面介绍\n\n<img class=\"bigimg\" src=\"\\img\\QQ截图20210318111958.png\" alt=\"QQ截图20210318111958\" style=\"zoom:150%;\" />\n\nProjects(项目)：项目包含作业，工作流和数据流等子对象，项目是Data Services的最高级对象，主要用于组织管理子对象，一个项目通常包含多个作业\n\nJob(作业)：可独立安排执行的最小工作单元。 作业由工作流和数据流组成，这些工作流和数据流按顺序和指定方式处理流程。\n\nWork flows(工作流)：工作流指定处理数据流的顺序。将下级数据流安排在工作流下，以便一个数据流的输出准备好输入到预期数据流。\n\nData flows(数据流)：数据流是将源数据转换为目标数据的过程。数据流按在工作流中排列的顺序处理数据。数据流定义了数据服务需要完成的基本任务。 基本任务是将数据从一个或多个源移动到一个或多个目标表或文件。通过标识提取数据的源，数据应进行的转换以及目标来定义数据流。\n\n######   Data Services对象列表\n\n<img src=\"\\img\\20200811154500211.png\" alt=\"20200811154500211\" style=\"zoom:70%;\" />\n\n######   对象层级以及从属关系\n\n<img src=\"\\img\\20200811154704891.png\" alt=\"20200811154704891\" style=\"zoom:100%;\" />\n\n##### DS数据加载方式\n\n将演示最基本的从其他系统中抽取数据到SAP HANA中（多图预警）\n\n*注：~~如何创建datastores连接其他系统和数据库此文不进行阐述~~*，下面的演示为全量抽取，将一次将表中的全部数据抽取到你想要的数据库里。\n\n根据对象层级以及从属关系来创建\n\n*也可以直接在local object library点击不同的对象独立创建~~（但不推荐，因为不好管理也不好找）~~*\n\n首先创建project，在local object library界面中选择project，然后空白处选择New\n\n<img src=\"\\img\\QQ截图20210318164049.png\" alt=\"QQ截图20210318164049\" style=\"zoom:50%;\" />\n\n起一个你喜欢的名字（project name）*~~见名知意，最好再加上注释🙏~~*，然后点击create（创建）\n\n<img src=\"\\img\\QQ截图20210318164227.png\" alt=\"QQ截图20210318164227\" style=\"zoom:50%;\" />\n\n之后再local object library中右击刚刚创建的project，点击open（打开）\n\n<img src=\"\\img\\QQ截图20210318164346.png\" alt=\"QQ截图20210318164346\" style=\"zoom:50%;\" />\n\n它就会在project Area上显示树状图\n\n<img src=\"\\img\\QQ截图20210318170041.png\" alt=\"QQ截图20210318170041\" style=\"zoom:50%;\" />\n\n之后右击空白位置或者project选择new batch job（新建批量作业）\n\n<img src=\"\\img\\QQ截图20210318170601.png\" alt=\"QQ截图20210318170601\" style=\"zoom:50%;\" />\n\n通常名字和要进行的业务相关 ~~见名知意~~（这就是我们需要执行的作业，可以手动或者定时执行\n\n<img src=\"\\img\\QQ截图20210318170649.png\" alt=\"QQ截图20210318170649\" style=\"zoom:50%;\" />\n\n之后双击就应该会在右侧工作区打开，应该是一片空白，空无一物，这时我们就需要点击右侧工具区的Dataflow（数据流），然后到空白区域左键单击新建一个df，名字一般应和你要抽取的表同名，比如说：DF_XXXX\n\n<img src=\"\\img\\QQ截图20210318171011.png\" alt=\"QQ截图20210318171011\" style=\"zoom:50%;\" />\n\n之后鼠标双击你刚才新建的df进入df的工作区，准备开始抽取表数据\n\n###### 流程：\n\n1. 在你要抽取数据的datastore中右键tables—import by name创建source表（源数据表，也就是你要抽取的表）。\n2. 鼠标左键拖拽到df工作区，选择Make Source(作为源表)  。\n3. 然后在右侧工具区拖拽query对数据进行处理（~~也可以跳过query，不进行输入处理，直接将源表和目标表连线~~\n4. 从右侧工具区拖拽template(临时表)到df工具区，填上你想要抽到哪个datastore和schema。\n5. 保存执行\n\n###### 示例：\n\n步骤一：\n\n在datastore导入表\n\n<img src=\"\\img\\QQ截图20210319085415.png\" alt=\"QQ截图20210319085415\" style=\"zoom:50%;\" />\n\n填写表的信息，之后点击import导入\n\n<img src=\"\\img\\QQ截图20210319085849.png\" alt=\"QQ截图20210319085849\" style=\"zoom:50%;\" />\n\n步骤二：\n\n鼠标拖拽刚刚导入的表到右侧ds工作区，选择make source作为源表\n\n<img src=\"\\img\\QQ截图20210319090259.png\" alt=\"QQ截图20210319090259\" style=\"zoom:50%;\" />\n\n最后是这个样子的，中间图示的表格深蓝色而且清晰，绿色箭头向右\n\n<img src=\"\\img\\QQ截图20210319090340.png\" alt=\"QQ截图20210319090340\" style=\"zoom:50%;\" />\n\n步骤三：\n\n点击工具区中的query，鼠标图标应该会发生改变，随后点击df的工作区创建一个query\n\n<img src=\"\\img\\QQ截图20210319090825.png\" alt=\"QQ截图20210319090825\" style=\"zoom:50%;\" />\n\n之后通过鼠标悬浮到源表右侧的小点，鼠标图标应该会变换成一个拿着粉笔的手，随后左键单击拖拽就应该会出现连线，将线连接到query控件左侧的三角形\n\n<img src=\"\\img\\QQ截图20210319091413.png\" alt=\"QQ截图20210319091413\" style=\"zoom:50%;\" />\n\n随后双击进入query，对数据进行处理\n\n<img src=\"\\img\\QQ截图20210319091622.png\" alt=\"QQ截图20210319091622\" style=\"zoom: 50%;\" />\n\n步骤四：\n\n也是通过左键工具区中的template（临时表）到ds工作区，填写要抽到库里的表名和schema，表名应和要抽取的表同名\n\n<img src=\"\\img\\QQ截图20210319092829.png\" alt=\"QQ截图20210319092829\" style=\"zoom: 50%;\" />\n\n随后通过query连线到临时表，最后应该是这样子的\n\n<img src=\"\\img\\QQ截图20210319093220.png\" alt=\"QQ截图20210319093220\" style=\"zoom:50%;\" />\n\n双击右侧的临时表，点击options，拖到最下方吧这一行改为YES！~~不然字符串的数据抽取可能出现问题~~\n\n<img src=\"\\img\\QQ截图20210319093541.png\" alt=\"QQ截图20210319093541\" style=\"zoom:33%;\" />\n\n<img src=\"\\img\\QQ截图20210319093607.png\" alt=\"QQ截图20210319093607\" style=\"zoom:50%;\" />\n\n步骤五：\n\n到job页面或者在左侧project area右键job选运行。如果没保存会提示让你保存，随后执行，点ok\n\n<img src=\"\\img\\QQ截图20210319094058.png\" alt=\"QQ截图20210319094058\" style=\"zoom:50%;\" />\n\n<img src=\"\\img\\QQ截图20210319094206.png\" alt=\"QQ截图20210319094206\" style=\"zoom:50%;\" />\n\n保存执行！\n\n本文中展示数据皆为示例，不太具有实际参考价值，但步骤相同，推荐举一反三。\n\n[部分引自SAP Data Services Designer - Ⅰ（User interface and Setting）](https://blog.csdn.net/JanoZhuo/article/details/107934029)\n\n<img class=\"litimg\" src=\"\\img\\fdacab61d58425e368f30729feb2d2c8.jpg\" alt=\"fdacab61d58425e368f30729feb2d2c8\" style=\"zoom:50%;\" />\n\nこの何もないの世界に、お前わ何が欲しいのが\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"SAP-Data-Services-Designer","published":1,"updated":"2021-03-22T08:07:10.536Z","_id":"ckmk0reyz0004ekvs8g2thay5","comments":1,"layout":"post","photos":[],"link":"","content":"<h5><span id=\"sap-data-services-designer工具介绍和基础使用抽表\">SAP DATA SERVICES DESIGNER工具介绍和基础使用（抽表）</span></h5><p>接下来简称DS</p>\n<p>SAP BusinessObjects Data Service 是通过SAP HANA认证的ETL工具。采用数据批量处理的方式，定期执行后台作业，将数据从多个业务系统中抽取出来，并进行必要的处理（转换，合并，过滤，清晰），然后在加载到HANA数据库中。</p>\n<p>DS组件之间的关系：</p>\n<img src=\"\\img\\20200811145254657.png\" alt=\"20200811145254657\" style=\"zoom:60%;\">\n\n<table>\n<thead>\n<tr>\n<th align=\"left\">Designer</th>\n<th>用户可在此界面1. 创建、测试以及执行填充数据仓库的作业<br>2. 创建并通过拖拽的方法连接对象形成流程图<br>3. 在流程图中打开编辑修改对象的配置<br>4. 定义数据映像、转换以及逻辑控制<br>5. 通过将对象组合到工作流（作业执行定义）和数据流（数据转换定义）中来创建应用程序</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Job Server</td>\n<td>启动数据服务处理的引擎以及数据服务套件与其他组件的接口的引擎的应用程序。</td>\n</tr>\n<tr>\n<td align=\"left\">Engine</td>\n<td>执行在Designer中定义的各个作业，以有效地完成已定义的任务。</td>\n</tr>\n<tr>\n<td align=\"left\">Repository</td>\n<td>存储Designer预定义系统对象和用户定义对象（包括源和目标元数据以及转换规则）的数据库。 创建一个本地存储库，然后创建一个中央存储库，以与其他用户共享对象并进行版本控制。</td>\n</tr>\n<tr>\n<td align=\"left\">Access Server</td>\n<td>在Web应用程序与数据服务作业服务器和引擎之间传递消息。 提供用于请求响应处理的可靠且可扩展的接口。</td>\n</tr>\n<tr>\n<td align=\"left\">Administrator</td>\n<td>提供以下基于浏览器的数据服务资源管理的Web管理员：<br>1. 计划，监视和执行批处理作业<br>2. 配置，启动和停止实时服务<br>3. 配置作业服务器，访问服务器和存储库使用情况<br>4. 配置和管理适配器<br>5. 管理用户<br>6. 通过Web服务发布批处理作业和实时服务</td>\n</tr>\n</tbody></table>\n<h6><span id=\"用户界面介绍\">用户界面介绍</span></h6><img class=\"bigimg\" src=\"\\img\\QQ截图20210318111958.png\" alt=\"QQ截图20210318111958\" style=\"zoom:150%;\">\n\n<p>Projects(项目)：项目包含作业，工作流和数据流等子对象，项目是Data Services的最高级对象，主要用于组织管理子对象，一个项目通常包含多个作业</p>\n<p>Job(作业)：可独立安排执行的最小工作单元。 作业由工作流和数据流组成，这些工作流和数据流按顺序和指定方式处理流程。</p>\n<p>Work flows(工作流)：工作流指定处理数据流的顺序。将下级数据流安排在工作流下，以便一个数据流的输出准备好输入到预期数据流。</p>\n<p>Data flows(数据流)：数据流是将源数据转换为目标数据的过程。数据流按在工作流中排列的顺序处理数据。数据流定义了数据服务需要完成的基本任务。 基本任务是将数据从一个或多个源移动到一个或多个目标表或文件。通过标识提取数据的源，数据应进行的转换以及目标来定义数据流。</p>\n<h6><span id=\"data-services对象列表\">Data Services对象列表</span></h6><img src=\"\\img\\20200811154500211.png\" alt=\"20200811154500211\" style=\"zoom:70%;\">\n\n<h6><span id=\"对象层级以及从属关系\">对象层级以及从属关系</span></h6><img src=\"\\img\\20200811154704891.png\" alt=\"20200811154704891\" style=\"zoom:100%;\">\n\n<h5><span id=\"ds数据加载方式\">DS数据加载方式</span></h5><p>将演示最基本的从其他系统中抽取数据到SAP HANA中（多图预警）</p>\n<p>*注：<del>如何创建datastores连接其他系统和数据库此文不进行阐述</del>*，下面的演示为全量抽取，将一次将表中的全部数据抽取到你想要的数据库里。</p>\n<p>根据对象层级以及从属关系来创建</p>\n<p><em>也可以直接在local object library点击不同的对象独立创建<del>（但不推荐，因为不好管理也不好找）</del></em></p>\n<p>首先创建project，在local object library界面中选择project，然后空白处选择New</p>\n<img src=\"\\img\\QQ截图20210318164049.png\" alt=\"QQ截图20210318164049\" style=\"zoom:50%;\">\n\n<p>起一个你喜欢的名字（project name）*<del>见名知意，最好再加上注释🙏</del>*，然后点击create（创建）</p>\n<img src=\"\\img\\QQ截图20210318164227.png\" alt=\"QQ截图20210318164227\" style=\"zoom:50%;\">\n\n<p>之后再local object library中右击刚刚创建的project，点击open（打开）</p>\n<img src=\"\\img\\QQ截图20210318164346.png\" alt=\"QQ截图20210318164346\" style=\"zoom:50%;\">\n\n<p>它就会在project Area上显示树状图</p>\n<img src=\"\\img\\QQ截图20210318170041.png\" alt=\"QQ截图20210318170041\" style=\"zoom:50%;\">\n\n<p>之后右击空白位置或者project选择new batch job（新建批量作业）</p>\n<img src=\"\\img\\QQ截图20210318170601.png\" alt=\"QQ截图20210318170601\" style=\"zoom:50%;\">\n\n<p>通常名字和要进行的业务相关 <del>见名知意</del>（这就是我们需要执行的作业，可以手动或者定时执行</p>\n<img src=\"\\img\\QQ截图20210318170649.png\" alt=\"QQ截图20210318170649\" style=\"zoom:50%;\">\n\n<p>之后双击就应该会在右侧工作区打开，应该是一片空白，空无一物，这时我们就需要点击右侧工具区的Dataflow（数据流），然后到空白区域左键单击新建一个df，名字一般应和你要抽取的表同名，比如说：DF_XXXX</p>\n<img src=\"\\img\\QQ截图20210318171011.png\" alt=\"QQ截图20210318171011\" style=\"zoom:50%;\">\n\n<p>之后鼠标双击你刚才新建的df进入df的工作区，准备开始抽取表数据</p>\n<h6><span id=\"流程\">流程：</span></h6><ol>\n<li>在你要抽取数据的datastore中右键tables—import by name创建source表（源数据表，也就是你要抽取的表）。</li>\n<li>鼠标左键拖拽到df工作区，选择Make Source(作为源表)  。</li>\n<li>然后在右侧工具区拖拽query对数据进行处理（<del>也可以跳过query，不进行输入处理，直接将源表和目标表连线</del></li>\n<li>从右侧工具区拖拽template(临时表)到df工具区，填上你想要抽到哪个datastore和schema。</li>\n<li>保存执行</li>\n</ol>\n<h6><span id=\"示例\">示例：</span></h6><p>步骤一：</p>\n<p>在datastore导入表</p>\n<img src=\"\\img\\QQ截图20210319085415.png\" alt=\"QQ截图20210319085415\" style=\"zoom:50%;\">\n\n<p>填写表的信息，之后点击import导入</p>\n<img src=\"\\img\\QQ截图20210319085849.png\" alt=\"QQ截图20210319085849\" style=\"zoom:50%;\">\n\n<p>步骤二：</p>\n<p>鼠标拖拽刚刚导入的表到右侧ds工作区，选择make source作为源表</p>\n<img src=\"\\img\\QQ截图20210319090259.png\" alt=\"QQ截图20210319090259\" style=\"zoom:50%;\">\n\n<p>最后是这个样子的，中间图示的表格深蓝色而且清晰，绿色箭头向右</p>\n<img src=\"\\img\\QQ截图20210319090340.png\" alt=\"QQ截图20210319090340\" style=\"zoom:50%;\">\n\n<p>步骤三：</p>\n<p>点击工具区中的query，鼠标图标应该会发生改变，随后点击df的工作区创建一个query</p>\n<img src=\"\\img\\QQ截图20210319090825.png\" alt=\"QQ截图20210319090825\" style=\"zoom:50%;\">\n\n<p>之后通过鼠标悬浮到源表右侧的小点，鼠标图标应该会变换成一个拿着粉笔的手，随后左键单击拖拽就应该会出现连线，将线连接到query控件左侧的三角形</p>\n<img src=\"\\img\\QQ截图20210319091413.png\" alt=\"QQ截图20210319091413\" style=\"zoom:50%;\">\n\n<p>随后双击进入query，对数据进行处理</p>\n<img src=\"\\img\\QQ截图20210319091622.png\" alt=\"QQ截图20210319091622\" style=\"zoom: 50%;\">\n\n<p>步骤四：</p>\n<p>也是通过左键工具区中的template（临时表）到ds工作区，填写要抽到库里的表名和schema，表名应和要抽取的表同名</p>\n<img src=\"\\img\\QQ截图20210319092829.png\" alt=\"QQ截图20210319092829\" style=\"zoom: 50%;\">\n\n<p>随后通过query连线到临时表，最后应该是这样子的</p>\n<img src=\"\\img\\QQ截图20210319093220.png\" alt=\"QQ截图20210319093220\" style=\"zoom:50%;\">\n\n<p>双击右侧的临时表，点击options，拖到最下方吧这一行改为YES！<del>不然字符串的数据抽取可能出现问题</del></p>\n<img src=\"\\img\\QQ截图20210319093541.png\" alt=\"QQ截图20210319093541\" style=\"zoom:33%;\">\n\n<img src=\"\\img\\QQ截图20210319093607.png\" alt=\"QQ截图20210319093607\" style=\"zoom:50%;\">\n\n<p>步骤五：</p>\n<p>到job页面或者在左侧project area右键job选运行。如果没保存会提示让你保存，随后执行，点ok</p>\n<img src=\"\\img\\QQ截图20210319094058.png\" alt=\"QQ截图20210319094058\" style=\"zoom:50%;\">\n\n<img src=\"\\img\\QQ截图20210319094206.png\" alt=\"QQ截图20210319094206\" style=\"zoom:50%;\">\n\n<p>保存执行！</p>\n<p>本文中展示数据皆为示例，不太具有实际参考价值，但步骤相同，推荐举一反三。</p>\n<p><a href=\"https://blog.csdn.net/JanoZhuo/article/details/107934029\">部分引自SAP Data Services Designer - Ⅰ（User interface and Setting）</a></p>\n<img class=\"litimg\" src=\"\\img\\fdacab61d58425e368f30729feb2d2c8.jpg\" alt=\"fdacab61d58425e368f30729feb2d2c8\" style=\"zoom:50%;\">\n\n<p>この何もないの世界に、お前わ何が欲しいのが</p>\n","site":{"data":{}},"excerpt":"","more":"<h5 id=\"SAP-DATA-SERVICES-DESIGNER工具介绍和基础使用（抽表）\"><a href=\"#SAP-DATA-SERVICES-DESIGNER工具介绍和基础使用（抽表）\" class=\"headerlink\" title=\"SAP DATA SERVICES DESIGNER工具介绍和基础使用（抽表）\"></a>SAP DATA SERVICES DESIGNER工具介绍和基础使用（抽表）</h5><p>接下来简称DS</p>\n<p>SAP BusinessObjects Data Service 是通过SAP HANA认证的ETL工具。采用数据批量处理的方式，定期执行后台作业，将数据从多个业务系统中抽取出来，并进行必要的处理（转换，合并，过滤，清晰），然后在加载到HANA数据库中。</p>\n<p>DS组件之间的关系：</p>\n<img src=\"\\img\\20200811145254657.png\" alt=\"20200811145254657\" style=\"zoom:60%;\" />\n\n<table>\n<thead>\n<tr>\n<th align=\"left\">Designer</th>\n<th>用户可在此界面1. 创建、测试以及执行填充数据仓库的作业<br/>2. 创建并通过拖拽的方法连接对象形成流程图<br/>3. 在流程图中打开编辑修改对象的配置<br/>4. 定义数据映像、转换以及逻辑控制<br/>5. 通过将对象组合到工作流（作业执行定义）和数据流（数据转换定义）中来创建应用程序</th>\n</tr>\n</thead>\n<tbody><tr>\n<td align=\"left\">Job Server</td>\n<td>启动数据服务处理的引擎以及数据服务套件与其他组件的接口的引擎的应用程序。</td>\n</tr>\n<tr>\n<td align=\"left\">Engine</td>\n<td>执行在Designer中定义的各个作业，以有效地完成已定义的任务。</td>\n</tr>\n<tr>\n<td align=\"left\">Repository</td>\n<td>存储Designer预定义系统对象和用户定义对象（包括源和目标元数据以及转换规则）的数据库。 创建一个本地存储库，然后创建一个中央存储库，以与其他用户共享对象并进行版本控制。</td>\n</tr>\n<tr>\n<td align=\"left\">Access Server</td>\n<td>在Web应用程序与数据服务作业服务器和引擎之间传递消息。 提供用于请求响应处理的可靠且可扩展的接口。</td>\n</tr>\n<tr>\n<td align=\"left\">Administrator</td>\n<td>提供以下基于浏览器的数据服务资源管理的Web管理员：<br/>1. 计划，监视和执行批处理作业<br/>2. 配置，启动和停止实时服务<br/>3. 配置作业服务器，访问服务器和存储库使用情况<br/>4. 配置和管理适配器<br/>5. 管理用户<br/>6. 通过Web服务发布批处理作业和实时服务</td>\n</tr>\n</tbody></table>\n<h6 id=\"用户界面介绍\"><a href=\"#用户界面介绍\" class=\"headerlink\" title=\"用户界面介绍\"></a>用户界面介绍</h6><img class=\"bigimg\" src=\"\\img\\QQ截图20210318111958.png\" alt=\"QQ截图20210318111958\" style=\"zoom:150%;\" />\n\n<p>Projects(项目)：项目包含作业，工作流和数据流等子对象，项目是Data Services的最高级对象，主要用于组织管理子对象，一个项目通常包含多个作业</p>\n<p>Job(作业)：可独立安排执行的最小工作单元。 作业由工作流和数据流组成，这些工作流和数据流按顺序和指定方式处理流程。</p>\n<p>Work flows(工作流)：工作流指定处理数据流的顺序。将下级数据流安排在工作流下，以便一个数据流的输出准备好输入到预期数据流。</p>\n<p>Data flows(数据流)：数据流是将源数据转换为目标数据的过程。数据流按在工作流中排列的顺序处理数据。数据流定义了数据服务需要完成的基本任务。 基本任务是将数据从一个或多个源移动到一个或多个目标表或文件。通过标识提取数据的源，数据应进行的转换以及目标来定义数据流。</p>\n<h6 id=\"Data-Services对象列表\"><a href=\"#Data-Services对象列表\" class=\"headerlink\" title=\"Data Services对象列表\"></a>Data Services对象列表</h6><img src=\"\\img\\20200811154500211.png\" alt=\"20200811154500211\" style=\"zoom:70%;\" />\n\n<h6 id=\"对象层级以及从属关系\"><a href=\"#对象层级以及从属关系\" class=\"headerlink\" title=\"对象层级以及从属关系\"></a>对象层级以及从属关系</h6><img src=\"\\img\\20200811154704891.png\" alt=\"20200811154704891\" style=\"zoom:100%;\" />\n\n<h5 id=\"DS数据加载方式\"><a href=\"#DS数据加载方式\" class=\"headerlink\" title=\"DS数据加载方式\"></a>DS数据加载方式</h5><p>将演示最基本的从其他系统中抽取数据到SAP HANA中（多图预警）</p>\n<p>*注：<del>如何创建datastores连接其他系统和数据库此文不进行阐述</del>*，下面的演示为全量抽取，将一次将表中的全部数据抽取到你想要的数据库里。</p>\n<p>根据对象层级以及从属关系来创建</p>\n<p><em>也可以直接在local object library点击不同的对象独立创建<del>（但不推荐，因为不好管理也不好找）</del></em></p>\n<p>首先创建project，在local object library界面中选择project，然后空白处选择New</p>\n<img src=\"\\img\\QQ截图20210318164049.png\" alt=\"QQ截图20210318164049\" style=\"zoom:50%;\" />\n\n<p>起一个你喜欢的名字（project name）*<del>见名知意，最好再加上注释🙏</del>*，然后点击create（创建）</p>\n<img src=\"\\img\\QQ截图20210318164227.png\" alt=\"QQ截图20210318164227\" style=\"zoom:50%;\" />\n\n<p>之后再local object library中右击刚刚创建的project，点击open（打开）</p>\n<img src=\"\\img\\QQ截图20210318164346.png\" alt=\"QQ截图20210318164346\" style=\"zoom:50%;\" />\n\n<p>它就会在project Area上显示树状图</p>\n<img src=\"\\img\\QQ截图20210318170041.png\" alt=\"QQ截图20210318170041\" style=\"zoom:50%;\" />\n\n<p>之后右击空白位置或者project选择new batch job（新建批量作业）</p>\n<img src=\"\\img\\QQ截图20210318170601.png\" alt=\"QQ截图20210318170601\" style=\"zoom:50%;\" />\n\n<p>通常名字和要进行的业务相关 <del>见名知意</del>（这就是我们需要执行的作业，可以手动或者定时执行</p>\n<img src=\"\\img\\QQ截图20210318170649.png\" alt=\"QQ截图20210318170649\" style=\"zoom:50%;\" />\n\n<p>之后双击就应该会在右侧工作区打开，应该是一片空白，空无一物，这时我们就需要点击右侧工具区的Dataflow（数据流），然后到空白区域左键单击新建一个df，名字一般应和你要抽取的表同名，比如说：DF_XXXX</p>\n<img src=\"\\img\\QQ截图20210318171011.png\" alt=\"QQ截图20210318171011\" style=\"zoom:50%;\" />\n\n<p>之后鼠标双击你刚才新建的df进入df的工作区，准备开始抽取表数据</p>\n<h6 id=\"流程：\"><a href=\"#流程：\" class=\"headerlink\" title=\"流程：\"></a>流程：</h6><ol>\n<li>在你要抽取数据的datastore中右键tables—import by name创建source表（源数据表，也就是你要抽取的表）。</li>\n<li>鼠标左键拖拽到df工作区，选择Make Source(作为源表)  。</li>\n<li>然后在右侧工具区拖拽query对数据进行处理（<del>也可以跳过query，不进行输入处理，直接将源表和目标表连线</del></li>\n<li>从右侧工具区拖拽template(临时表)到df工具区，填上你想要抽到哪个datastore和schema。</li>\n<li>保存执行</li>\n</ol>\n<h6 id=\"示例：\"><a href=\"#示例：\" class=\"headerlink\" title=\"示例：\"></a>示例：</h6><p>步骤一：</p>\n<p>在datastore导入表</p>\n<img src=\"\\img\\QQ截图20210319085415.png\" alt=\"QQ截图20210319085415\" style=\"zoom:50%;\" />\n\n<p>填写表的信息，之后点击import导入</p>\n<img src=\"\\img\\QQ截图20210319085849.png\" alt=\"QQ截图20210319085849\" style=\"zoom:50%;\" />\n\n<p>步骤二：</p>\n<p>鼠标拖拽刚刚导入的表到右侧ds工作区，选择make source作为源表</p>\n<img src=\"\\img\\QQ截图20210319090259.png\" alt=\"QQ截图20210319090259\" style=\"zoom:50%;\" />\n\n<p>最后是这个样子的，中间图示的表格深蓝色而且清晰，绿色箭头向右</p>\n<img src=\"\\img\\QQ截图20210319090340.png\" alt=\"QQ截图20210319090340\" style=\"zoom:50%;\" />\n\n<p>步骤三：</p>\n<p>点击工具区中的query，鼠标图标应该会发生改变，随后点击df的工作区创建一个query</p>\n<img src=\"\\img\\QQ截图20210319090825.png\" alt=\"QQ截图20210319090825\" style=\"zoom:50%;\" />\n\n<p>之后通过鼠标悬浮到源表右侧的小点，鼠标图标应该会变换成一个拿着粉笔的手，随后左键单击拖拽就应该会出现连线，将线连接到query控件左侧的三角形</p>\n<img src=\"\\img\\QQ截图20210319091413.png\" alt=\"QQ截图20210319091413\" style=\"zoom:50%;\" />\n\n<p>随后双击进入query，对数据进行处理</p>\n<img src=\"\\img\\QQ截图20210319091622.png\" alt=\"QQ截图20210319091622\" style=\"zoom: 50%;\" />\n\n<p>步骤四：</p>\n<p>也是通过左键工具区中的template（临时表）到ds工作区，填写要抽到库里的表名和schema，表名应和要抽取的表同名</p>\n<img src=\"\\img\\QQ截图20210319092829.png\" alt=\"QQ截图20210319092829\" style=\"zoom: 50%;\" />\n\n<p>随后通过query连线到临时表，最后应该是这样子的</p>\n<img src=\"\\img\\QQ截图20210319093220.png\" alt=\"QQ截图20210319093220\" style=\"zoom:50%;\" />\n\n<p>双击右侧的临时表，点击options，拖到最下方吧这一行改为YES！<del>不然字符串的数据抽取可能出现问题</del></p>\n<img src=\"\\img\\QQ截图20210319093541.png\" alt=\"QQ截图20210319093541\" style=\"zoom:33%;\" />\n\n<img src=\"\\img\\QQ截图20210319093607.png\" alt=\"QQ截图20210319093607\" style=\"zoom:50%;\" />\n\n<p>步骤五：</p>\n<p>到job页面或者在左侧project area右键job选运行。如果没保存会提示让你保存，随后执行，点ok</p>\n<img src=\"\\img\\QQ截图20210319094058.png\" alt=\"QQ截图20210319094058\" style=\"zoom:50%;\" />\n\n<img src=\"\\img\\QQ截图20210319094206.png\" alt=\"QQ截图20210319094206\" style=\"zoom:50%;\" />\n\n<p>保存执行！</p>\n<p>本文中展示数据皆为示例，不太具有实际参考价值，但步骤相同，推荐举一反三。</p>\n<p><a href=\"https://blog.csdn.net/JanoZhuo/article/details/107934029\">部分引自SAP Data Services Designer - Ⅰ（User interface and Setting）</a></p>\n<img class=\"litimg\" src=\"\\img\\fdacab61d58425e368f30729feb2d2c8.jpg\" alt=\"fdacab61d58425e368f30729feb2d2c8\" style=\"zoom:50%;\" />\n\n<p>この何もないの世界に、お前わ何が欲しいのが</p>\n"},{"title":"Hello World","_content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","source":"_posts/hello-world.md","raw":"---\ntitle: Hello World\ntags:\n  - life\n---\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n","slug":"hello-world","published":1,"date":"2021-03-05T06:24:57.040Z","updated":"2021-03-22T06:35:29.968Z","_id":"ckmk0rez00005ekvsa6hh8o2s","comments":1,"layout":"post","photos":[],"link":"","content":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2><span id=\"quick-start\">Quick Start</span></h2><h3><span id=\"create-a-new-post\">Create a new post</span></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3><span id=\"run-server\">Run server</span></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3><span id=\"generate-static-files\">Generate static files</span></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3><span id=\"deploy-to-remote-sites\">Deploy to remote sites</span></h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>Welcome to <a href=\"https://hexo.io/\">Hexo</a>! This is your very first post. Check <a href=\"https://hexo.io/docs/\">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href=\"https://hexo.io/docs/troubleshooting.html\">troubleshooting</a> or you can ask me on <a href=\"https://github.com/hexojs/hexo/issues\">GitHub</a>.</p>\n<h2 id=\"Quick-Start\"><a href=\"#Quick-Start\" class=\"headerlink\" title=\"Quick Start\"></a>Quick Start</h2><h3 id=\"Create-a-new-post\"><a href=\"#Create-a-new-post\" class=\"headerlink\" title=\"Create a new post\"></a>Create a new post</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo new <span class=\"string\">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/writing.html\">Writing</a></p>\n<h3 id=\"Run-server\"><a href=\"#Run-server\" class=\"headerlink\" title=\"Run server\"></a>Run server</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo server</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/server.html\">Server</a></p>\n<h3 id=\"Generate-static-files\"><a href=\"#Generate-static-files\" class=\"headerlink\" title=\"Generate static files\"></a>Generate static files</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo generate</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/generating.html\">Generating</a></p>\n<h3 id=\"Deploy-to-remote-sites\"><a href=\"#Deploy-to-remote-sites\" class=\"headerlink\" title=\"Deploy to remote sites\"></a>Deploy to remote sites</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ hexo deploy</span><br></pre></td></tr></table></figure>\n\n<p>More info: <a href=\"https://hexo.io/docs/one-command-deployment.html\">Deployment</a></p>\n"},{"title":"wHo i'M I","date":"2021-03-08T06:48:00.000Z","_content":"\n我的生活是一个圆，是一个泡沫，而我在泡沫的中间。","source":"_posts/wHo-i-M-I.md","raw":"---\ntitle: wHo i'M I\ndate: 2021-03-08 14:48:00\ntags:\n  - life\n---\n\n我的生活是一个圆，是一个泡沫，而我在泡沫的中间。","slug":"wHo-i-M-I","published":1,"updated":"2021-03-19T07:22:58.563Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckmk0rez40007ekvs9t9r6jnh","content":"<p>我的生活是一个圆，是一个泡沫，而我在泡沫的中间。</p>\n","site":{"data":{}},"excerpt":"","more":"<p>我的生活是一个圆，是一个泡沫，而我在泡沫的中间。</p>\n"},{"title":"开窗函数","date":"2021-03-15T00:59:23.000Z","_content":"\n##### 排序函数\n\n开窗函数over()，包含三个分析子句:分组(partition by), 排序(order by), 窗口(rows) ，他们的使用形式如下：over(partition by 排序字段 order by 分区字段 rows between 开窗规则)。\n\n开窗函数     \n   Oracle从8.1.6开始提供分析函数，分析函数用于计算基于组的某种聚合值，它和聚合函数的不同之处是：对于每个组返回多行，而聚合函数对于每个组只返回一行。\n\n   开窗函数指定了分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化，\n\n示例数据：\n\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\" />\n\n第一大类：**聚合开窗函数**====》聚合函数(列) OVER (选项)\n\n：sum(),count()等都可以拼接\n\n第二大类：**排序开窗函数**====》排序函数(列) OVER(选项)\n\n：rank(),row_number()等需要和over一起使用排序函数\n\n***不限于此，很多函数都可以配合over（），在这里不做过多介绍***\n\n语法：\n\n```sql\n--select 函数名()over(partition by 需要分区的列名 order by 想排序的列名 rows/range \n --unbounded preceding and unbouned following针对当前所有记录的前一条、后一条记录，也就是表中的所有记录\n            --unbounded：不受控制的，无限的\n            --preceding：在...之前\n            --following：在...之后\n          --  BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) from 表名\n--such as \nselect *,sum(sage)over(order by sage rows between UNBOUNDED preceding and UNBOUNDED following)\nfrom \"student\"\n```\n\n**分区（partition by ）：**\n\n功能与group by几乎相同，但group by对于聚合的分组只显示一行数据，并且select后的字段如果其中一个被group by，那么其他字段要么是聚合函数要么也被group by分组聚合。\n\n栗子：分别求男女同学年龄总和\n\n<img src=\"\\img\\QQ截图20210315093653.png\" alt=\"QQ截图20210315093653\" style=\"zoom:80%;\" />\n\n而聚合函数搭配over（）可以一组返回多行数据，而且其他字段不需要为被分组或被聚合。\n\n\n\n**排序（order by）：**\n\n栗子：男女分别根据年龄降序排列\n\n<img src=\"\\img\\QQ截图20210315100337.png\" alt=\"QQ截图20210315100337\" style=\"zoom:80%;\" />\n\n\n\n没什么需要多说的，这里使用了rank()函数排序，partition by相当于group by，order by还是原意。\n\n注：关于rank()等排序函数请移步其他文章，本文不做说明\n\n栗子ii：男女按照年龄降序分别求出年龄累计\n\n<img src=\"\\img\\QQ截图20210315135813.png\" alt=\"QQ截图20210315135813\" style=\"zoom:80%;\" />\n\n这里发生了变化，当使用sum()或count()配合over使用，并且使用partition by和order by，就会根据排序进行逐渐的累加或者求和，可以用于计算各个月份随时间累计数等情况\n\n\n\n**窗口（rows/range）注：rows可以使用，但是range没研究明白报错：**\n\n在Over子句中，使用Rows 或Range 进一步限制分区的数据行，在使用时，必须注意：\n\n必需条件：如果使用Rows 或 Range必须跟在Order by 子句之后，对排序的结果进行限制；\nRows：使用固定的行数来限制分区中的数据行数量；The ROWS clause limits the rows within a partition by specifying a fixed number of rows preceding or following the current row.\nRange：使用Value的范围来限制分区中的数据行数量，排序列的重复值，被认为是一个值；The RANGE clause logically limits the rows within a partition by specifying a range of values with respect to the value in the current row.\n在分区中，如果排序行不存在重复值，Rows和Range返回的结果是相同的；如果排序行存储在重复值，Rows和Range返回的结果可能不同；\nRange子句只能从分区的开始或结尾到当前行开始计算，不能使用 <UINT_Number> PRECEDING 和<UINT_Number>  FOLLOWING；\n使用在Rows 和 Range子句中的特殊关键字：\n\nUNBOUNDED PRECEDING：指定分区的第一行\nUNBOUNDED FOLLOWING：指定分区的最后一行\nCURRENT ROW：指定分区的当前数据行\n<UINT_Number> PRECEDING：在分区中，指定当前行之前的数据行数量，UINT_Number是>=0的整数\n<UINT_Number> FOLLOWING：在分区中，指定当前行之后的数据行数量，UINT_Number是>=0的整数\n\n```sql\n--每行数据都会被开窗影响，每行数据都会根据开窗的行数来向上或向下进行函数的操作。\n--当上面没有行时上面的行不做影响，下面也没有行时同上。\nselect *,sum(sage)over(order by sage rows between 前多少行 preceding and 后多少行 following)\nfrom \"student\"\n```\n\n栗子：对分区中的连续两行计算加和，将每行和下一行进行相加\n\n<img src=\"\\img\\QQ截图20210315150441.png\" alt=\"QQ截图20210315150441\" style=\"zoom:80%;\" />\n\n第一行=第一行sage+第二行sage，第二行=第二行sage+第三行sage...........以此类推\n\n图中第五行数据和第十行数据都是分区中的最后一行数据，没有下面的行进行相加所以是原数\n\n--栗子ii：对分区中的当前行向下计算加和，将每行到当前分区最底下的进行相加\n\nCould not execute 'select *,sum(sage)over(order by sage range between unbounded preceding and unbounded following) ...'\nSAP DBTech JDBC: [7]: feature not supported: Window frame specification of RANGE not allowed for this window function: line 1 col 10 (at pos 9)\n\n<img src=\"\\img\\202005241421367251716257711.500x0.jpg.webp\" alt=\"202005241421367251716257711.500x0.jpg.webp\" />\n\n# **<u>*to* *be* continued（多半是鸽了😜 </u>**","source":"_posts/开窗函数.md","raw":"---\ntitle: 开窗函数\ndate: 2021-03-15 08:59:23\ntags:\n  - study\n  - sql\n---\n\n##### 排序函数\n\n开窗函数over()，包含三个分析子句:分组(partition by), 排序(order by), 窗口(rows) ，他们的使用形式如下：over(partition by 排序字段 order by 分区字段 rows between 开窗规则)。\n\n开窗函数     \n   Oracle从8.1.6开始提供分析函数，分析函数用于计算基于组的某种聚合值，它和聚合函数的不同之处是：对于每个组返回多行，而聚合函数对于每个组只返回一行。\n\n   开窗函数指定了分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化，\n\n示例数据：\n\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\" />\n\n第一大类：**聚合开窗函数**====》聚合函数(列) OVER (选项)\n\n：sum(),count()等都可以拼接\n\n第二大类：**排序开窗函数**====》排序函数(列) OVER(选项)\n\n：rank(),row_number()等需要和over一起使用排序函数\n\n***不限于此，很多函数都可以配合over（），在这里不做过多介绍***\n\n语法：\n\n```sql\n--select 函数名()over(partition by 需要分区的列名 order by 想排序的列名 rows/range \n --unbounded preceding and unbouned following针对当前所有记录的前一条、后一条记录，也就是表中的所有记录\n            --unbounded：不受控制的，无限的\n            --preceding：在...之前\n            --following：在...之后\n          --  BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) from 表名\n--such as \nselect *,sum(sage)over(order by sage rows between UNBOUNDED preceding and UNBOUNDED following)\nfrom \"student\"\n```\n\n**分区（partition by ）：**\n\n功能与group by几乎相同，但group by对于聚合的分组只显示一行数据，并且select后的字段如果其中一个被group by，那么其他字段要么是聚合函数要么也被group by分组聚合。\n\n栗子：分别求男女同学年龄总和\n\n<img src=\"\\img\\QQ截图20210315093653.png\" alt=\"QQ截图20210315093653\" style=\"zoom:80%;\" />\n\n而聚合函数搭配over（）可以一组返回多行数据，而且其他字段不需要为被分组或被聚合。\n\n\n\n**排序（order by）：**\n\n栗子：男女分别根据年龄降序排列\n\n<img src=\"\\img\\QQ截图20210315100337.png\" alt=\"QQ截图20210315100337\" style=\"zoom:80%;\" />\n\n\n\n没什么需要多说的，这里使用了rank()函数排序，partition by相当于group by，order by还是原意。\n\n注：关于rank()等排序函数请移步其他文章，本文不做说明\n\n栗子ii：男女按照年龄降序分别求出年龄累计\n\n<img src=\"\\img\\QQ截图20210315135813.png\" alt=\"QQ截图20210315135813\" style=\"zoom:80%;\" />\n\n这里发生了变化，当使用sum()或count()配合over使用，并且使用partition by和order by，就会根据排序进行逐渐的累加或者求和，可以用于计算各个月份随时间累计数等情况\n\n\n\n**窗口（rows/range）注：rows可以使用，但是range没研究明白报错：**\n\n在Over子句中，使用Rows 或Range 进一步限制分区的数据行，在使用时，必须注意：\n\n必需条件：如果使用Rows 或 Range必须跟在Order by 子句之后，对排序的结果进行限制；\nRows：使用固定的行数来限制分区中的数据行数量；The ROWS clause limits the rows within a partition by specifying a fixed number of rows preceding or following the current row.\nRange：使用Value的范围来限制分区中的数据行数量，排序列的重复值，被认为是一个值；The RANGE clause logically limits the rows within a partition by specifying a range of values with respect to the value in the current row.\n在分区中，如果排序行不存在重复值，Rows和Range返回的结果是相同的；如果排序行存储在重复值，Rows和Range返回的结果可能不同；\nRange子句只能从分区的开始或结尾到当前行开始计算，不能使用 <UINT_Number> PRECEDING 和<UINT_Number>  FOLLOWING；\n使用在Rows 和 Range子句中的特殊关键字：\n\nUNBOUNDED PRECEDING：指定分区的第一行\nUNBOUNDED FOLLOWING：指定分区的最后一行\nCURRENT ROW：指定分区的当前数据行\n<UINT_Number> PRECEDING：在分区中，指定当前行之前的数据行数量，UINT_Number是>=0的整数\n<UINT_Number> FOLLOWING：在分区中，指定当前行之后的数据行数量，UINT_Number是>=0的整数\n\n```sql\n--每行数据都会被开窗影响，每行数据都会根据开窗的行数来向上或向下进行函数的操作。\n--当上面没有行时上面的行不做影响，下面也没有行时同上。\nselect *,sum(sage)over(order by sage rows between 前多少行 preceding and 后多少行 following)\nfrom \"student\"\n```\n\n栗子：对分区中的连续两行计算加和，将每行和下一行进行相加\n\n<img src=\"\\img\\QQ截图20210315150441.png\" alt=\"QQ截图20210315150441\" style=\"zoom:80%;\" />\n\n第一行=第一行sage+第二行sage，第二行=第二行sage+第三行sage...........以此类推\n\n图中第五行数据和第十行数据都是分区中的最后一行数据，没有下面的行进行相加所以是原数\n\n--栗子ii：对分区中的当前行向下计算加和，将每行到当前分区最底下的进行相加\n\nCould not execute 'select *,sum(sage)over(order by sage range between unbounded preceding and unbounded following) ...'\nSAP DBTech JDBC: [7]: feature not supported: Window frame specification of RANGE not allowed for this window function: line 1 col 10 (at pos 9)\n\n<img src=\"\\img\\202005241421367251716257711.500x0.jpg.webp\" alt=\"202005241421367251716257711.500x0.jpg.webp\" />\n\n# **<u>*to* *be* continued（多半是鸽了😜 </u>**","slug":"开窗函数","published":1,"updated":"2021-03-22T08:07:03.885Z","_id":"ckmk0rez80008ekvs19j32w9k","comments":1,"layout":"post","photos":[],"link":"","content":"<h5><span id=\"排序函数\">排序函数</span></h5><p>开窗函数over()，包含三个分析子句:分组(partition by), 排序(order by), 窗口(rows) ，他们的使用形式如下：over(partition by 排序字段 order by 分区字段 rows between 开窗规则)。</p>\n<p>开窗函数<br>   Oracle从8.1.6开始提供分析函数，分析函数用于计算基于组的某种聚合值，它和聚合函数的不同之处是：对于每个组返回多行，而聚合函数对于每个组只返回一行。</p>\n<p>   开窗函数指定了分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化，</p>\n<p>示例数据：</p>\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\">\n\n<p>第一大类：<strong>聚合开窗函数</strong>====》聚合函数(列) OVER (选项)</p>\n<p>：sum(),count()等都可以拼接</p>\n<p>第二大类：<strong>排序开窗函数</strong>====》排序函数(列) OVER(选项)</p>\n<p>：rank(),row_number()等需要和over一起使用排序函数</p>\n<p><em><strong>不限于此，很多函数都可以配合over（），在这里不做过多介绍</strong></em></p>\n<p>语法：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">--select 函数名()over(partition by 需要分区的列名 order by 想排序的列名 rows/range </span></span><br><span class=\"line\"> <span class=\"comment\">--unbounded preceding and unbouned following针对当前所有记录的前一条、后一条记录，也就是表中的所有记录</span></span><br><span class=\"line\">            <span class=\"comment\">--unbounded：不受控制的，无限的</span></span><br><span class=\"line\">            <span class=\"comment\">--preceding：在...之前</span></span><br><span class=\"line\">            <span class=\"comment\">--following：在...之后</span></span><br><span class=\"line\">          <span class=\"comment\">--  BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) from 表名</span></span><br><span class=\"line\"><span class=\"comment\">--such as </span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span>,<span class=\"built_in\">sum</span>(sage)<span class=\"keyword\">over</span>(<span class=\"keyword\">order</span> <span class=\"keyword\">by</span> sage <span class=\"keyword\">rows</span> <span class=\"keyword\">between</span> UNBOUNDED preceding <span class=\"keyword\">and</span> UNBOUNDED following)</span><br><span class=\"line\"><span class=\"keyword\">from</span> &quot;student&quot;</span><br></pre></td></tr></table></figure>\n\n<p><strong>分区（partition by ）：</strong></p>\n<p>功能与group by几乎相同，但group by对于聚合的分组只显示一行数据，并且select后的字段如果其中一个被group by，那么其他字段要么是聚合函数要么也被group by分组聚合。</p>\n<p>栗子：分别求男女同学年龄总和</p>\n<img src=\"\\img\\QQ截图20210315093653.png\" alt=\"QQ截图20210315093653\" style=\"zoom:80%;\">\n\n<p>而聚合函数搭配over（）可以一组返回多行数据，而且其他字段不需要为被分组或被聚合。</p>\n<p><strong>排序（order by）：</strong></p>\n<p>栗子：男女分别根据年龄降序排列</p>\n<img src=\"\\img\\QQ截图20210315100337.png\" alt=\"QQ截图20210315100337\" style=\"zoom:80%;\">\n\n\n\n<p>没什么需要多说的，这里使用了rank()函数排序，partition by相当于group by，order by还是原意。</p>\n<p>注：关于rank()等排序函数请移步其他文章，本文不做说明</p>\n<p>栗子ii：男女按照年龄降序分别求出年龄累计</p>\n<img src=\"\\img\\QQ截图20210315135813.png\" alt=\"QQ截图20210315135813\" style=\"zoom:80%;\">\n\n<p>这里发生了变化，当使用sum()或count()配合over使用，并且使用partition by和order by，就会根据排序进行逐渐的累加或者求和，可以用于计算各个月份随时间累计数等情况</p>\n<p><strong>窗口（rows/range）注：rows可以使用，但是range没研究明白报错：</strong></p>\n<p>在Over子句中，使用Rows 或Range 进一步限制分区的数据行，在使用时，必须注意：</p>\n<p>必需条件：如果使用Rows 或 Range必须跟在Order by 子句之后，对排序的结果进行限制；<br>Rows：使用固定的行数来限制分区中的数据行数量；The ROWS clause limits the rows within a partition by specifying a fixed number of rows preceding or following the current row.<br>Range：使用Value的范围来限制分区中的数据行数量，排序列的重复值，被认为是一个值；The RANGE clause logically limits the rows within a partition by specifying a range of values with respect to the value in the current row.<br>在分区中，如果排序行不存在重复值，Rows和Range返回的结果是相同的；如果排序行存储在重复值，Rows和Range返回的结果可能不同；<br>Range子句只能从分区的开始或结尾到当前行开始计算，不能使用 <uint_number> PRECEDING 和<uint_number>  FOLLOWING；<br>使用在Rows 和 Range子句中的特殊关键字：</uint_number></uint_number></p>\n<p>UNBOUNDED PRECEDING：指定分区的第一行<br>UNBOUNDED FOLLOWING：指定分区的最后一行<br>CURRENT ROW：指定分区的当前数据行<br><uint_number> PRECEDING：在分区中，指定当前行之前的数据行数量，UINT_Number是&gt;=0的整数<br><uint_number> FOLLOWING：在分区中，指定当前行之后的数据行数量，UINT_Number是&gt;=0的整数</uint_number></uint_number></p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">--每行数据都会被开窗影响，每行数据都会根据开窗的行数来向上或向下进行函数的操作。</span></span><br><span class=\"line\"><span class=\"comment\">--当上面没有行时上面的行不做影响，下面也没有行时同上。</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span>,<span class=\"built_in\">sum</span>(sage)<span class=\"keyword\">over</span>(<span class=\"keyword\">order</span> <span class=\"keyword\">by</span> sage <span class=\"keyword\">rows</span> <span class=\"keyword\">between</span> 前多少行 preceding <span class=\"keyword\">and</span> 后多少行 following)</span><br><span class=\"line\"><span class=\"keyword\">from</span> &quot;student&quot;</span><br></pre></td></tr></table></figure>\n\n<p>栗子：对分区中的连续两行计算加和，将每行和下一行进行相加</p>\n<img src=\"\\img\\QQ截图20210315150441.png\" alt=\"QQ截图20210315150441\" style=\"zoom:80%;\">\n\n<p>第一行=第一行sage+第二行sage，第二行=第二行sage+第三行sage………..以此类推</p>\n<p>图中第五行数据和第十行数据都是分区中的最后一行数据，没有下面的行进行相加所以是原数</p>\n<p>–栗子ii：对分区中的当前行向下计算加和，将每行到当前分区最底下的进行相加</p>\n<p>Could not execute ‘select *,sum(sage)over(order by sage range between unbounded preceding and unbounded following) …’<br>SAP DBTech JDBC: [7]: feature not supported: Window frame specification of RANGE not allowed for this window function: line 1 col 10 (at pos 9)</p>\n<img src=\"\\img\\202005241421367251716257711.500x0.jpg.webp\" alt=\"202005241421367251716257711.500x0.jpg.webp\">\n\n<h1><span id=\"to-be-continued多半是鸽了\"><strong><u><em>to</em> <em>be</em> continued（多半是鸽了😜 </u></strong></span></h1>","site":{"data":{}},"excerpt":"","more":"<h5 id=\"排序函数\"><a href=\"#排序函数\" class=\"headerlink\" title=\"排序函数\"></a>排序函数</h5><p>开窗函数over()，包含三个分析子句:分组(partition by), 排序(order by), 窗口(rows) ，他们的使用形式如下：over(partition by 排序字段 order by 分区字段 rows between 开窗规则)。</p>\n<p>开窗函数<br>   Oracle从8.1.6开始提供分析函数，分析函数用于计算基于组的某种聚合值，它和聚合函数的不同之处是：对于每个组返回多行，而聚合函数对于每个组只返回一行。</p>\n<p>   开窗函数指定了分析函数工作的数据窗口大小，这个数据窗口大小可能会随着行的变化而变化，</p>\n<p>示例数据：</p>\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\" />\n\n<p>第一大类：<strong>聚合开窗函数</strong>====》聚合函数(列) OVER (选项)</p>\n<p>：sum(),count()等都可以拼接</p>\n<p>第二大类：<strong>排序开窗函数</strong>====》排序函数(列) OVER(选项)</p>\n<p>：rank(),row_number()等需要和over一起使用排序函数</p>\n<p><em><strong>不限于此，很多函数都可以配合over（），在这里不做过多介绍</strong></em></p>\n<p>语法：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">--select 函数名()over(partition by 需要分区的列名 order by 想排序的列名 rows/range </span></span><br><span class=\"line\"> <span class=\"comment\">--unbounded preceding and unbouned following针对当前所有记录的前一条、后一条记录，也就是表中的所有记录</span></span><br><span class=\"line\">            <span class=\"comment\">--unbounded：不受控制的，无限的</span></span><br><span class=\"line\">            <span class=\"comment\">--preceding：在...之前</span></span><br><span class=\"line\">            <span class=\"comment\">--following：在...之后</span></span><br><span class=\"line\">          <span class=\"comment\">--  BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) from 表名</span></span><br><span class=\"line\"><span class=\"comment\">--such as </span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span>,<span class=\"built_in\">sum</span>(sage)<span class=\"keyword\">over</span>(<span class=\"keyword\">order</span> <span class=\"keyword\">by</span> sage <span class=\"keyword\">rows</span> <span class=\"keyword\">between</span> UNBOUNDED preceding <span class=\"keyword\">and</span> UNBOUNDED following)</span><br><span class=\"line\"><span class=\"keyword\">from</span> &quot;student&quot;</span><br></pre></td></tr></table></figure>\n\n<p><strong>分区（partition by ）：</strong></p>\n<p>功能与group by几乎相同，但group by对于聚合的分组只显示一行数据，并且select后的字段如果其中一个被group by，那么其他字段要么是聚合函数要么也被group by分组聚合。</p>\n<p>栗子：分别求男女同学年龄总和</p>\n<img src=\"\\img\\QQ截图20210315093653.png\" alt=\"QQ截图20210315093653\" style=\"zoom:80%;\" />\n\n<p>而聚合函数搭配over（）可以一组返回多行数据，而且其他字段不需要为被分组或被聚合。</p>\n<p><strong>排序（order by）：</strong></p>\n<p>栗子：男女分别根据年龄降序排列</p>\n<img src=\"\\img\\QQ截图20210315100337.png\" alt=\"QQ截图20210315100337\" style=\"zoom:80%;\" />\n\n\n\n<p>没什么需要多说的，这里使用了rank()函数排序，partition by相当于group by，order by还是原意。</p>\n<p>注：关于rank()等排序函数请移步其他文章，本文不做说明</p>\n<p>栗子ii：男女按照年龄降序分别求出年龄累计</p>\n<img src=\"\\img\\QQ截图20210315135813.png\" alt=\"QQ截图20210315135813\" style=\"zoom:80%;\" />\n\n<p>这里发生了变化，当使用sum()或count()配合over使用，并且使用partition by和order by，就会根据排序进行逐渐的累加或者求和，可以用于计算各个月份随时间累计数等情况</p>\n<p><strong>窗口（rows/range）注：rows可以使用，但是range没研究明白报错：</strong></p>\n<p>在Over子句中，使用Rows 或Range 进一步限制分区的数据行，在使用时，必须注意：</p>\n<p>必需条件：如果使用Rows 或 Range必须跟在Order by 子句之后，对排序的结果进行限制；<br>Rows：使用固定的行数来限制分区中的数据行数量；The ROWS clause limits the rows within a partition by specifying a fixed number of rows preceding or following the current row.<br>Range：使用Value的范围来限制分区中的数据行数量，排序列的重复值，被认为是一个值；The RANGE clause logically limits the rows within a partition by specifying a range of values with respect to the value in the current row.<br>在分区中，如果排序行不存在重复值，Rows和Range返回的结果是相同的；如果排序行存储在重复值，Rows和Range返回的结果可能不同；<br>Range子句只能从分区的开始或结尾到当前行开始计算，不能使用 <UINT_Number> PRECEDING 和<UINT_Number>  FOLLOWING；<br>使用在Rows 和 Range子句中的特殊关键字：</p>\n<p>UNBOUNDED PRECEDING：指定分区的第一行<br>UNBOUNDED FOLLOWING：指定分区的最后一行<br>CURRENT ROW：指定分区的当前数据行<br><UINT_Number> PRECEDING：在分区中，指定当前行之前的数据行数量，UINT_Number是&gt;=0的整数<br><UINT_Number> FOLLOWING：在分区中，指定当前行之后的数据行数量，UINT_Number是&gt;=0的整数</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">--每行数据都会被开窗影响，每行数据都会根据开窗的行数来向上或向下进行函数的操作。</span></span><br><span class=\"line\"><span class=\"comment\">--当上面没有行时上面的行不做影响，下面也没有行时同上。</span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"operator\">*</span>,<span class=\"built_in\">sum</span>(sage)<span class=\"keyword\">over</span>(<span class=\"keyword\">order</span> <span class=\"keyword\">by</span> sage <span class=\"keyword\">rows</span> <span class=\"keyword\">between</span> 前多少行 preceding <span class=\"keyword\">and</span> 后多少行 following)</span><br><span class=\"line\"><span class=\"keyword\">from</span> &quot;student&quot;</span><br></pre></td></tr></table></figure>\n\n<p>栗子：对分区中的连续两行计算加和，将每行和下一行进行相加</p>\n<img src=\"\\img\\QQ截图20210315150441.png\" alt=\"QQ截图20210315150441\" style=\"zoom:80%;\" />\n\n<p>第一行=第一行sage+第二行sage，第二行=第二行sage+第三行sage………..以此类推</p>\n<p>图中第五行数据和第十行数据都是分区中的最后一行数据，没有下面的行进行相加所以是原数</p>\n<p>–栗子ii：对分区中的当前行向下计算加和，将每行到当前分区最底下的进行相加</p>\n<p>Could not execute ‘select *,sum(sage)over(order by sage range between unbounded preceding and unbounded following) …’<br>SAP DBTech JDBC: [7]: feature not supported: Window frame specification of RANGE not allowed for this window function: line 1 col 10 (at pos 9)</p>\n<img src=\"\\img\\202005241421367251716257711.500x0.jpg.webp\" alt=\"202005241421367251716257711.500x0.jpg.webp\" />\n\n<h1 id=\"to-be-continued（多半是鸽了😜\"><a href=\"#to-be-continued（多半是鸽了😜\" class=\"headerlink\" title=\"to be continued（多半是鸽了😜 \"></a><strong><u><em>to</em> <em>be</em> continued（多半是鸽了😜 </u></strong></h1>"},{"title":"排序函数","date":"2021-03-12T00:42:58.000Z","_content":"\n##### 排序函数：\n\n  排序函数的作用是基于一个结果集返回一个排序值。排序值就是一个数字，这个数字是典型的以1开始且自增长为1的行值。由排序函数来决定排序值。可以使唯一的对于当前结果集，或者某些行数据有相同的排序值。接下来介绍不同的排序函数以及如何使用这些函数。\n\n示例数据：\n\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\" />\n\n语法：\n\n```sql\n--select 函数名()over(order by 想排序的列名) from 表名\n--such as \nselect rank()over(partition by ssex order by sage desc) \nfrom \"student\"\n```\n\n*注：over（）开窗函数用法在此文中不进行介绍*\n\n###### **ROW_NUMBER()**\n\n**定义**：ROW_NUMBER()函数作用就是将select查询到的数据进行排序，每一条数据加一个序号，他不能用做于学生年龄的排名，一般多用于分页查询，因为在遇到相同年龄时序号依然会继续自增，而非并列的序号。\n\n**栗子：**根据年龄降序排列学生\n\n<img src=\"\\img\\QQ截图20210312145034.png\" alt=\"QQ截图20210312145034\" style=\"zoom:80%;\" />\n\nROW_NUMBER（）当遇到相同年龄时序号依然会自增\n\n###### **RANK()**\n\n**定义：**RANK()函数，顾名思义排名函数，可以对某一个字段进行排名，与ROW_NUMBER()不同，当存在相同年龄的学生时，ROW_NUMBER()会继续进行排序，他们的序号不相同，而Rank()则不一样，当出现相同的年龄时，他们的排名是一样的，并且会跳过已经占用的序号。\n\n**栗子：**根据年龄降序排列学生\n\n<img src=\"\\img\\QQ截图20210312145927.png\" alt=\"QQ截图20210312145927\" style=\"zoom:80%;\" />\n\n*这里第五条数据突然从2号序号跳跃到5号序号，是因为上面已经有四位同学被排序过，按照已经被排序的数据条数就是5号*\n\nRANK（）当遇到相同年龄时序号时序号不会自增，而是和相同年龄时的序号相同。同时当再次向下排序遇到不同年龄时，会根据已进行排序的条数来跳跃序号。\n\n###### **DENSE_RANK()**\n\n**定义**：DENSE_RANK()函数也是排名函数，和RANK()功能相似，也是对字段进行排名，那它和RANK()到底有什么不同那？\n\n**栗子：**根据年龄降序排列学生\n\n<img src=\"\\img\\QQ截图20210312150624.png\" alt=\"QQ截图20210312150624\" style=\"zoom:80%;\" />\n\ndense_rank函数的功能与rank函数类似，dense_rank函数在生成序号时是连续的，而rank函数生成的序号有可能不连续。dense_rank函数出现相同排名时，将不跳过相同排名号，rank值紧接上一次的rank值。在各个分组内，rank()是跳跃排序，有两个第一名时接下来就是第四名，dense_rank()是连续排序，有两个第一名时仍然跟着第二名。\n\n**NTILE()**\n\n**定义**：ntile函数可以对序号进行分组处理，将有序分区中的行分发到指定数目的组中。 各个组有编号，编号从一开始。 对于每一个行，ntile 将返回此行所属的组的编号。这就相当于将查询出来的记录集放到指定长度的数组中，每一个数组元素存放一定数量的记录。ntile函数为每条记录生成的序号就是这条记录所有的数组元素的索引（从1开始）。也可以将每一个分配记录的数组元素称为“桶”。ntile函数有一个参数，用来指定桶数。\n\n<img src=\"\\img\\QQ截图20210312160137.png\" alt=\"QQ截图20210312160137\" style=\"zoom:80%;\" />\n\n*将年龄降序并且平均分为四个桶（区）*\n\n　　ntile函数的分组依据（约定）：\n\n　　**1、每组的记录数不能大于它上一组的记录数，即编号小的桶放的记录数不能小于编号大的桶。就是说，第1组中的记录数只能大于等于第2组及以后各组中的记录数。**\n\n　　**2、所有组中的记录数要么都相同，要么从某一个记录较少的组（命名为X）开始后面所有组的记录数都与该组（X组）的记录数相同。也就是说，如果有个组，前三组的记录数都是9，而第四组的记录数是8，那么第五组和第六组的记录数也必须是8。**\n\n以上为四个排序函数的用法，最后一个可能不算排序，而是根据排序内容分桶，应用场景一般不为排序。而这些排序函数都依赖于over分窗函数，可以看到排序都是在它之中进行的，同时它也可以使用partition by排序的同时分组，类似于group by，也可以根据row和range进行开窗，但这里不过多解释。！\n\n**总结：**\n\n在使用排名函数的时候需要注意以下三点：\n\n　　1、排名函数必须有 OVER 子句。\n\n　　2、排名函数必须有包含 ORDER BY 的 OVER 子句。\n\n　　3、分组内从1开始排序。\n\n[引自[Sql 四大排名函数（ROW_NUMBER、RANK、DENSE_RANK、NTILE）简介]](https://www.cnblogs.com/52XF/p/4209211.html)\n\n<img src=\"\\img\\20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png\" alt=\"20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef\" style=\"zoom:33%;\" />\n\n","source":"_posts/排序函数.md","raw":"---\ntitle: 排序函数\ndate: 2021-03-12 08:42:58\ntags:\n  - study\n  - sql\n---\n\n##### 排序函数：\n\n  排序函数的作用是基于一个结果集返回一个排序值。排序值就是一个数字，这个数字是典型的以1开始且自增长为1的行值。由排序函数来决定排序值。可以使唯一的对于当前结果集，或者某些行数据有相同的排序值。接下来介绍不同的排序函数以及如何使用这些函数。\n\n示例数据：\n\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\" />\n\n语法：\n\n```sql\n--select 函数名()over(order by 想排序的列名) from 表名\n--such as \nselect rank()over(partition by ssex order by sage desc) \nfrom \"student\"\n```\n\n*注：over（）开窗函数用法在此文中不进行介绍*\n\n###### **ROW_NUMBER()**\n\n**定义**：ROW_NUMBER()函数作用就是将select查询到的数据进行排序，每一条数据加一个序号，他不能用做于学生年龄的排名，一般多用于分页查询，因为在遇到相同年龄时序号依然会继续自增，而非并列的序号。\n\n**栗子：**根据年龄降序排列学生\n\n<img src=\"\\img\\QQ截图20210312145034.png\" alt=\"QQ截图20210312145034\" style=\"zoom:80%;\" />\n\nROW_NUMBER（）当遇到相同年龄时序号依然会自增\n\n###### **RANK()**\n\n**定义：**RANK()函数，顾名思义排名函数，可以对某一个字段进行排名，与ROW_NUMBER()不同，当存在相同年龄的学生时，ROW_NUMBER()会继续进行排序，他们的序号不相同，而Rank()则不一样，当出现相同的年龄时，他们的排名是一样的，并且会跳过已经占用的序号。\n\n**栗子：**根据年龄降序排列学生\n\n<img src=\"\\img\\QQ截图20210312145927.png\" alt=\"QQ截图20210312145927\" style=\"zoom:80%;\" />\n\n*这里第五条数据突然从2号序号跳跃到5号序号，是因为上面已经有四位同学被排序过，按照已经被排序的数据条数就是5号*\n\nRANK（）当遇到相同年龄时序号时序号不会自增，而是和相同年龄时的序号相同。同时当再次向下排序遇到不同年龄时，会根据已进行排序的条数来跳跃序号。\n\n###### **DENSE_RANK()**\n\n**定义**：DENSE_RANK()函数也是排名函数，和RANK()功能相似，也是对字段进行排名，那它和RANK()到底有什么不同那？\n\n**栗子：**根据年龄降序排列学生\n\n<img src=\"\\img\\QQ截图20210312150624.png\" alt=\"QQ截图20210312150624\" style=\"zoom:80%;\" />\n\ndense_rank函数的功能与rank函数类似，dense_rank函数在生成序号时是连续的，而rank函数生成的序号有可能不连续。dense_rank函数出现相同排名时，将不跳过相同排名号，rank值紧接上一次的rank值。在各个分组内，rank()是跳跃排序，有两个第一名时接下来就是第四名，dense_rank()是连续排序，有两个第一名时仍然跟着第二名。\n\n**NTILE()**\n\n**定义**：ntile函数可以对序号进行分组处理，将有序分区中的行分发到指定数目的组中。 各个组有编号，编号从一开始。 对于每一个行，ntile 将返回此行所属的组的编号。这就相当于将查询出来的记录集放到指定长度的数组中，每一个数组元素存放一定数量的记录。ntile函数为每条记录生成的序号就是这条记录所有的数组元素的索引（从1开始）。也可以将每一个分配记录的数组元素称为“桶”。ntile函数有一个参数，用来指定桶数。\n\n<img src=\"\\img\\QQ截图20210312160137.png\" alt=\"QQ截图20210312160137\" style=\"zoom:80%;\" />\n\n*将年龄降序并且平均分为四个桶（区）*\n\n　　ntile函数的分组依据（约定）：\n\n　　**1、每组的记录数不能大于它上一组的记录数，即编号小的桶放的记录数不能小于编号大的桶。就是说，第1组中的记录数只能大于等于第2组及以后各组中的记录数。**\n\n　　**2、所有组中的记录数要么都相同，要么从某一个记录较少的组（命名为X）开始后面所有组的记录数都与该组（X组）的记录数相同。也就是说，如果有个组，前三组的记录数都是9，而第四组的记录数是8，那么第五组和第六组的记录数也必须是8。**\n\n以上为四个排序函数的用法，最后一个可能不算排序，而是根据排序内容分桶，应用场景一般不为排序。而这些排序函数都依赖于over分窗函数，可以看到排序都是在它之中进行的，同时它也可以使用partition by排序的同时分组，类似于group by，也可以根据row和range进行开窗，但这里不过多解释。！\n\n**总结：**\n\n在使用排名函数的时候需要注意以下三点：\n\n　　1、排名函数必须有 OVER 子句。\n\n　　2、排名函数必须有包含 ORDER BY 的 OVER 子句。\n\n　　3、分组内从1开始排序。\n\n[引自[Sql 四大排名函数（ROW_NUMBER、RANK、DENSE_RANK、NTILE）简介]](https://www.cnblogs.com/52XF/p/4209211.html)\n\n<img src=\"\\img\\20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png\" alt=\"20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef\" style=\"zoom:33%;\" />\n\n","slug":"排序函数","published":1,"updated":"2021-03-22T08:07:07.024Z","_id":"ckmk0rez90009ekvsd6tn2rev","comments":1,"layout":"post","photos":[],"link":"","content":"<h5><span id=\"排序函数\">排序函数：</span></h5><p>  排序函数的作用是基于一个结果集返回一个排序值。排序值就是一个数字，这个数字是典型的以1开始且自增长为1的行值。由排序函数来决定排序值。可以使唯一的对于当前结果集，或者某些行数据有相同的排序值。接下来介绍不同的排序函数以及如何使用这些函数。</p>\n<p>示例数据：</p>\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\">\n\n<p>语法：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">--select 函数名()over(order by 想排序的列名) from 表名</span></span><br><span class=\"line\"><span class=\"comment\">--such as </span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"built_in\">rank</span>()<span class=\"keyword\">over</span>(<span class=\"keyword\">partition</span> <span class=\"keyword\">by</span> ssex <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> sage <span class=\"keyword\">desc</span>) </span><br><span class=\"line\"><span class=\"keyword\">from</span> &quot;student&quot;</span><br></pre></td></tr></table></figure>\n\n<p><em>注：over（）开窗函数用法在此文中不进行介绍</em></p>\n<h6><span id=\"row_number\"><strong>ROW_NUMBER()</strong></span></h6><p><strong>定义</strong>：ROW_NUMBER()函数作用就是将select查询到的数据进行排序，每一条数据加一个序号，他不能用做于学生年龄的排名，一般多用于分页查询，因为在遇到相同年龄时序号依然会继续自增，而非并列的序号。</p>\n<p><strong>栗子：</strong>根据年龄降序排列学生</p>\n<img src=\"\\img\\QQ截图20210312145034.png\" alt=\"QQ截图20210312145034\" style=\"zoom:80%;\">\n\n<p>ROW_NUMBER（）当遇到相同年龄时序号依然会自增</p>\n<h6><span id=\"rank\"><strong>RANK()</strong></span></h6><p><strong>定义：</strong>RANK()函数，顾名思义排名函数，可以对某一个字段进行排名，与ROW_NUMBER()不同，当存在相同年龄的学生时，ROW_NUMBER()会继续进行排序，他们的序号不相同，而Rank()则不一样，当出现相同的年龄时，他们的排名是一样的，并且会跳过已经占用的序号。</p>\n<p><strong>栗子：</strong>根据年龄降序排列学生</p>\n<img src=\"\\img\\QQ截图20210312145927.png\" alt=\"QQ截图20210312145927\" style=\"zoom:80%;\">\n\n<p><em>这里第五条数据突然从2号序号跳跃到5号序号，是因为上面已经有四位同学被排序过，按照已经被排序的数据条数就是5号</em></p>\n<p>RANK（）当遇到相同年龄时序号时序号不会自增，而是和相同年龄时的序号相同。同时当再次向下排序遇到不同年龄时，会根据已进行排序的条数来跳跃序号。</p>\n<h6><span id=\"dense_rank\"><strong>DENSE_RANK()</strong></span></h6><p><strong>定义</strong>：DENSE_RANK()函数也是排名函数，和RANK()功能相似，也是对字段进行排名，那它和RANK()到底有什么不同那？</p>\n<p><strong>栗子：</strong>根据年龄降序排列学生</p>\n<img src=\"\\img\\QQ截图20210312150624.png\" alt=\"QQ截图20210312150624\" style=\"zoom:80%;\">\n\n<p>dense_rank函数的功能与rank函数类似，dense_rank函数在生成序号时是连续的，而rank函数生成的序号有可能不连续。dense_rank函数出现相同排名时，将不跳过相同排名号，rank值紧接上一次的rank值。在各个分组内，rank()是跳跃排序，有两个第一名时接下来就是第四名，dense_rank()是连续排序，有两个第一名时仍然跟着第二名。</p>\n<p><strong>NTILE()</strong></p>\n<p><strong>定义</strong>：ntile函数可以对序号进行分组处理，将有序分区中的行分发到指定数目的组中。 各个组有编号，编号从一开始。 对于每一个行，ntile 将返回此行所属的组的编号。这就相当于将查询出来的记录集放到指定长度的数组中，每一个数组元素存放一定数量的记录。ntile函数为每条记录生成的序号就是这条记录所有的数组元素的索引（从1开始）。也可以将每一个分配记录的数组元素称为“桶”。ntile函数有一个参数，用来指定桶数。</p>\n<img src=\"\\img\\QQ截图20210312160137.png\" alt=\"QQ截图20210312160137\" style=\"zoom:80%;\">\n\n<p><em>将年龄降序并且平均分为四个桶（区）</em></p>\n<p>　　ntile函数的分组依据（约定）：</p>\n<p>　　<strong>1、每组的记录数不能大于它上一组的记录数，即编号小的桶放的记录数不能小于编号大的桶。就是说，第1组中的记录数只能大于等于第2组及以后各组中的记录数。</strong></p>\n<p>　　<strong>2、所有组中的记录数要么都相同，要么从某一个记录较少的组（命名为X）开始后面所有组的记录数都与该组（X组）的记录数相同。也就是说，如果有个组，前三组的记录数都是9，而第四组的记录数是8，那么第五组和第六组的记录数也必须是8。</strong></p>\n<p>以上为四个排序函数的用法，最后一个可能不算排序，而是根据排序内容分桶，应用场景一般不为排序。而这些排序函数都依赖于over分窗函数，可以看到排序都是在它之中进行的，同时它也可以使用partition by排序的同时分组，类似于group by，也可以根据row和range进行开窗，但这里不过多解释。！</p>\n<p><strong>总结：</strong></p>\n<p>在使用排名函数的时候需要注意以下三点：</p>\n<p>　　1、排名函数必须有 OVER 子句。</p>\n<p>　　2、排名函数必须有包含 ORDER BY 的 OVER 子句。</p>\n<p>　　3、分组内从1开始排序。</p>\n<p><a href=\"https://www.cnblogs.com/52XF/p/4209211.html\">引自[Sql 四大排名函数（ROW_NUMBER、RANK、DENSE_RANK、NTILE）简介]</a></p>\n<img src=\"\\img\\20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png\" alt=\"20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef\" style=\"zoom:33%;\">\n\n","site":{"data":{}},"excerpt":"","more":"<h5 id=\"排序函数：\"><a href=\"#排序函数：\" class=\"headerlink\" title=\"排序函数：\"></a>排序函数：</h5><p>  排序函数的作用是基于一个结果集返回一个排序值。排序值就是一个数字，这个数字是典型的以1开始且自增长为1的行值。由排序函数来决定排序值。可以使唯一的对于当前结果集，或者某些行数据有相同的排序值。接下来介绍不同的排序函数以及如何使用这些函数。</p>\n<p>示例数据：</p>\n<img src=\"\\img\\QQ截图20210312144133.png\" alt=\"QQ截图20210312144133\" style=\"zoom:80%;\" />\n\n<p>语法：</p>\n<figure class=\"highlight sql\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">--select 函数名()over(order by 想排序的列名) from 表名</span></span><br><span class=\"line\"><span class=\"comment\">--such as </span></span><br><span class=\"line\"><span class=\"keyword\">select</span> <span class=\"built_in\">rank</span>()<span class=\"keyword\">over</span>(<span class=\"keyword\">partition</span> <span class=\"keyword\">by</span> ssex <span class=\"keyword\">order</span> <span class=\"keyword\">by</span> sage <span class=\"keyword\">desc</span>) </span><br><span class=\"line\"><span class=\"keyword\">from</span> &quot;student&quot;</span><br></pre></td></tr></table></figure>\n\n<p><em>注：over（）开窗函数用法在此文中不进行介绍</em></p>\n<h6 id=\"ROW-NUMBER\"><a href=\"#ROW-NUMBER\" class=\"headerlink\" title=\"ROW_NUMBER()\"></a><strong>ROW_NUMBER()</strong></h6><p><strong>定义</strong>：ROW_NUMBER()函数作用就是将select查询到的数据进行排序，每一条数据加一个序号，他不能用做于学生年龄的排名，一般多用于分页查询，因为在遇到相同年龄时序号依然会继续自增，而非并列的序号。</p>\n<p><strong>栗子：</strong>根据年龄降序排列学生</p>\n<img src=\"\\img\\QQ截图20210312145034.png\" alt=\"QQ截图20210312145034\" style=\"zoom:80%;\" />\n\n<p>ROW_NUMBER（）当遇到相同年龄时序号依然会自增</p>\n<h6 id=\"RANK\"><a href=\"#RANK\" class=\"headerlink\" title=\"RANK()\"></a><strong>RANK()</strong></h6><p><strong>定义：</strong>RANK()函数，顾名思义排名函数，可以对某一个字段进行排名，与ROW_NUMBER()不同，当存在相同年龄的学生时，ROW_NUMBER()会继续进行排序，他们的序号不相同，而Rank()则不一样，当出现相同的年龄时，他们的排名是一样的，并且会跳过已经占用的序号。</p>\n<p><strong>栗子：</strong>根据年龄降序排列学生</p>\n<img src=\"\\img\\QQ截图20210312145927.png\" alt=\"QQ截图20210312145927\" style=\"zoom:80%;\" />\n\n<p><em>这里第五条数据突然从2号序号跳跃到5号序号，是因为上面已经有四位同学被排序过，按照已经被排序的数据条数就是5号</em></p>\n<p>RANK（）当遇到相同年龄时序号时序号不会自增，而是和相同年龄时的序号相同。同时当再次向下排序遇到不同年龄时，会根据已进行排序的条数来跳跃序号。</p>\n<h6 id=\"DENSE-RANK\"><a href=\"#DENSE-RANK\" class=\"headerlink\" title=\"DENSE_RANK()\"></a><strong>DENSE_RANK()</strong></h6><p><strong>定义</strong>：DENSE_RANK()函数也是排名函数，和RANK()功能相似，也是对字段进行排名，那它和RANK()到底有什么不同那？</p>\n<p><strong>栗子：</strong>根据年龄降序排列学生</p>\n<img src=\"\\img\\QQ截图20210312150624.png\" alt=\"QQ截图20210312150624\" style=\"zoom:80%;\" />\n\n<p>dense_rank函数的功能与rank函数类似，dense_rank函数在生成序号时是连续的，而rank函数生成的序号有可能不连续。dense_rank函数出现相同排名时，将不跳过相同排名号，rank值紧接上一次的rank值。在各个分组内，rank()是跳跃排序，有两个第一名时接下来就是第四名，dense_rank()是连续排序，有两个第一名时仍然跟着第二名。</p>\n<p><strong>NTILE()</strong></p>\n<p><strong>定义</strong>：ntile函数可以对序号进行分组处理，将有序分区中的行分发到指定数目的组中。 各个组有编号，编号从一开始。 对于每一个行，ntile 将返回此行所属的组的编号。这就相当于将查询出来的记录集放到指定长度的数组中，每一个数组元素存放一定数量的记录。ntile函数为每条记录生成的序号就是这条记录所有的数组元素的索引（从1开始）。也可以将每一个分配记录的数组元素称为“桶”。ntile函数有一个参数，用来指定桶数。</p>\n<img src=\"\\img\\QQ截图20210312160137.png\" alt=\"QQ截图20210312160137\" style=\"zoom:80%;\" />\n\n<p><em>将年龄降序并且平均分为四个桶（区）</em></p>\n<p>　　ntile函数的分组依据（约定）：</p>\n<p>　　<strong>1、每组的记录数不能大于它上一组的记录数，即编号小的桶放的记录数不能小于编号大的桶。就是说，第1组中的记录数只能大于等于第2组及以后各组中的记录数。</strong></p>\n<p>　　<strong>2、所有组中的记录数要么都相同，要么从某一个记录较少的组（命名为X）开始后面所有组的记录数都与该组（X组）的记录数相同。也就是说，如果有个组，前三组的记录数都是9，而第四组的记录数是8，那么第五组和第六组的记录数也必须是8。</strong></p>\n<p>以上为四个排序函数的用法，最后一个可能不算排序，而是根据排序内容分桶，应用场景一般不为排序。而这些排序函数都依赖于over分窗函数，可以看到排序都是在它之中进行的，同时它也可以使用partition by排序的同时分组，类似于group by，也可以根据row和range进行开窗，但这里不过多解释。！</p>\n<p><strong>总结：</strong></p>\n<p>在使用排名函数的时候需要注意以下三点：</p>\n<p>　　1、排名函数必须有 OVER 子句。</p>\n<p>　　2、排名函数必须有包含 ORDER BY 的 OVER 子句。</p>\n<p>　　3、分组内从1开始排序。</p>\n<p><a href=\"https://www.cnblogs.com/52XF/p/4209211.html\">引自[Sql 四大排名函数（ROW_NUMBER、RANK、DENSE_RANK、NTILE）简介]</a></p>\n<img src=\"\\img\\20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef.png\" alt=\"20200429013947.52ff80ba8cacf5780b8e9e93e02e02ef\" style=\"zoom:33%;\" />\n\n"},{"title":"蛋","date":"2021-03-22T03:23:56.000Z","notshow":true,"_content":"\na\n\n","source":"_posts/蛋.md","raw":"---\ntitle: 蛋\ndate: 2021-03-22 11:23:56\ntags:\n  - life\nnotshow: true\n---\n\na\n\n","slug":"蛋","published":1,"updated":"2021-03-22T05:55:24.991Z","_id":"ckmk1092q0000qwvsg0cf1jaq","comments":1,"layout":"post","photos":[],"link":"","content":"<p>a</p>\n","site":{"data":{}},"excerpt":"","more":"<p>a</p>\n"},{"title":"python爬虫-爬取steam统计数据（steam游戏在线人数）","date":"2021-03-22T08:10:24.000Z","_content":"\n[转自[阿里波特]-[Python爬虫小白入门]](https://www.cnblogs.com/Albert-Lee/p/6226699.html)\n\n# 前言\n\n------\n\n你是不是在为想收集数据而不知道如何收集而着急？\n\n你是不是在为想学习爬虫而找不到一个专门为小白写的教程而烦恼？\n\nBingo! 你没有看错，这就是专门面向小白学习爬虫而写的！我会采用实例的方式，把每个部分都跟实际的例子结合起来帮助小伙伴儿们理解。最后再写几个实战的例子。\n\n我们使用Python来写爬虫，一方面因为Python是一个特别适合变成入门的语言，另一方面，Python也有很多爬虫相关的工具包，能够简单快速的开发出我们的小爬虫。\n本系列采用Python3.5版本，毕竟2.7会慢慢退出历史舞台~\n\n那么，接下来，你得知道什么是爬虫、爬虫从哪里爬取数据的，以及，学习爬虫都要学习哪些东西。\n\n# 什么是爬虫\n\n------\n\n来看看百度百科是如何定义的\n\n> [网络爬虫](http://baike.baidu.com/view/284853.htm)（又被称为网页[蜘蛛](http://baike.baidu.com/subview/8483/5395928.htm)，网络机器人，在[FOAF](http://baike.baidu.com/view/271451.htm)社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取[万维网](http://baike.baidu.com/view/7833.htm)信息的程序或者脚本。另外一些不常使用的名字还有[蚂蚁](http://baike.baidu.com/subview/3312/6169348.htm)、自动索引、模拟程序或者[蠕虫](http://baike.baidu.com/view/2596.htm)。\n\n什么？没看懂？没关系，我来给你解释一下\n\n打开一个网页，里面有网页内容吧，想象一下，有个工具，可以把网页上的内容获取下来，存到你想要的地方，这个工具就是我们今天的主角：爬虫。\n\n这样是不是更清晰了呢？\n\n既然了解了爬虫是什么，那么爬虫是如何爬取数据的呢？\n\n# 爬虫是哪里爬取数据的\n\n------\n\n打开浏览器（强烈建议谷歌浏览器），找到浏览器地址栏，然后在里输入store.steampowered.com/stats/并回车，你会看到网页内容。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162126.png\" alt=\"QQ截图20210322162126\" style=\"zoom:100%;\" />\n\n摁下键盘上的F12打开开发调试工具,，然后点击元素。看到这些文字了吗？这才是网页最赤果果的样子。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162407.png\" alt=\"QQ截图20210322162407\" style=\"zoom:100%;\" />\n\n其实所有的网页都是HTML代码，只不过浏览器将这些代码解析成了上面的网页，我们的爬虫抓取的其实就是HTML代码中的文本。\n\n随后点击开发调试工具左上角的小鼠标图标，点击你想要爬取的数据，你就会在元素这一栏看到下面红框的地方，是你要爬取数据的本来模样。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162801.png\" alt=\"QQ截图20210322162801\" style=\"zoom:100%;\" />\n\n没错，我们的爬虫抓取的正是网页中的数据，你要知道你想要抓取什么数据，你的目标网站是什么，才可以把想法变成现实的。\n\n# 学习爬虫的必备知识\n\n------\n\n大家要先对以下内容有一定的了解再来学习爬虫哦，磨刀不误砍柴工\n\n- HTML\n  这个能够帮助你了解网页的结构，内容等。可以参考[W3School的教程](http://www.w3school.com.cn/html/index.asp)。\n- Python\n  如果有编程基础的小伙伴儿，推荐看一个[廖雪峰的Python教程](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000)就够了\n  没有编程基础的小伙伴，推荐看看视频教程（网易云课堂搜Python），然后再结合廖雪峰的教程，双管齐下。\n  其实知乎上总结的已经非常好了，我就不多唠叨了。[知乎-如何系统的自学Python](https://www.zhihu.com/question/29138020)\n- TCP/IP协议，HTTP协议\n  这些知识能够让你了解在网络请求和网络传输上的基本原理，了解就行，能够帮助今后写爬虫的时候理解爬虫的逻辑。\n  廖雪峰Python教程里也有简单介绍，可以参考：[TCP/IP简介](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014320037768360d53e4e935ca4a1f96eed1c896ad1217000)，[HTTP协议](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432011939547478fd5482deb47b08716557cc99764e0000)\n  想更深入学习的小伙伴儿可以去网上多搜搜相关的书籍哦\n\nOK, 下一步就开始我们的实战啦\n\n# requests 库的安装\n\n为什么要先说Requests库呢，因为这是个功能很强大的网络请求库，可以实现跟浏览器一样发送各种HTTP请求来获取网站的数据。网络上的模块、库、包指的都是同一种东西，所以后文中可能会在不同地方使用不同称谓，不要迷惑。\n\n直接使用Python3.5的小伙伴儿输入这个命令：\n`pip install requests`\n\n如果你机器上存在多个Python版本，要给Python3.5的版本安装requests库，需要输入以下命令：\n`py -3 -m pip install requests`\n\n好啦，requests库安装完毕，接下来我们会在实际例子中演示它的使用。想要深入了解requests模块的小伙伴也可以仔细阅读[英文官方文档](http://docs.python-requests.org/en/master/api/)，和[中文官方文档](http://docs.python-requests.org/zh_CN/latest/user/quickstart.html)，如果用到该文没有提到的功能，则查看文档即可。\n\n# 开工\n\n------\n\n新建一个文件，只要他的后缀为.py即可，名字选择你喜欢的就好。\n\n输入第一行代码来导入requests库：\n`import requests #导入requests库`\n\n然后用它来获取咱们的目标网页：\n\n```python\nr = requests.get('https://store.steampowered.com/stats/') #像目标url地址发送get请求，返回一个response对象\nprint(r.text) #r.text是http response的网页HTML\n```\n\n之后再文件目录打开cmd页面，指令运行\n\n`python xxxxx.py`\n\n执行完之后，底部会出现输出结果：\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322163703.png\" alt=\"QQ截图20210322163703\" style=\"zoom:70%;\" />\n\n可以看到底部是获取到的网页内容。这就完成了爬虫的第一步，获取到了网页的HTML内容。\n\n这用到了requests库的get请求。其他请求使用也与之类似，但本文不进行阐述。\n\n我们刚才用requests库发送http请求获得了网页的HTML内容，那么应该如何从HTML中获得图片？\n\nBeautifulSoup库就此登场啦，赶快去来了解它的用法。\n\n刚才演示了如何使用requests模块向网站发送http请求，获取到网页的HTML数据。这篇来演示如何使用BeautifulSoup模块来从HTML文本中提取我们想要的数据。\n\n# 模块安装\n\n------\n\nBeautifulSoup 有多个版本，我们使用BeautifulSoup4。详细使用看[BeautifuSoup4官方文档](http://beautifulsoup.readthedocs.io/zh_CN/latest/)。\n使用管理员权限打开cmd命令窗口，在窗口中输入下面的命令即可安装：\n`pip install beautifulsoup4`\n\n然后我们安装lxml，这是一个解析器，BeautifulSoup可以使用它来解析HTML，然后提取内容。\n\n`pip install lxml`\n\n如果不安装lxml，则BeautifulSoup会使用Python内置的解析器对文档进行解析。之所以使用lxml，是因为它速度快。\n\n# BeautifulSoup 库的使用\n\n------\n\n网上找到的几个官方文档：[BeautifulSoup4.4.0中文官方文档](http://beautifulsoup.readthedocs.io/zh_CN/latest/)，[BeautifulSoup4.2.0中文官方文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)。不同版本的用法差不多，几个常用的语法都一样。\n\n首先来看BeautifulSoup的对象种类，在使用的过程中就会了解你获取到的东西接下来应该如何操作。\n\n## BeautifulSoup对象的类型\n\nBeautiful Soup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象。所有对象可以归纳为4种类型: Tag , NavigableString , BeautifulSoup , Comment 。下面我们分别看看这四种类型都是什么东西。\n\n### Tag\n\n这个就跟HTML或者XML（还能解析XML？是的，能！）中的标签是一样一样的。我们使用find()方法返回的类型就是这个（插一句：使用find-all()返回的是多个该对象的集合，是可以用for循环遍历的。）。返回标签之后，还可以对提取标签中的信息。\n\n###### 提取标签的名字：\n\n```javascript\ntag.name\n```\n\n###### 提取标签的属性：\n\n```javascript\ntag['attribute']\n```\n\n### NavigableString\n\nNavigableString就是标签中的文本内容（不包含标签）。获取方式如下：\n`tag.string`\n还是以上面那个例子，加上下面这行，然后执行：\n`print('NavigableString is：', find.string)`\n\n### BeautifulSoup\n\nBeautifulSoup对象表示一个文档的全部内容。支持遍历文档树和搜索文档树。\n\n### Comment\n\n这个对象其实就是HTML和XML中的注释。\n\n### 搜索文档树\n\n最常用的当然是find()和find_all()啦，当然还有其他的。比如find_parent() 和 find_parents()、 find_next_sibling() 和 find_next_siblings() 、find_all_next() 和 find_next()、find_all_previous() 和 find_previous() 等等。\n我们就看几个常用的，其余的如果用到就去看官方文档哦。\n\n- find_all()\n  搜索当前tag的所有tag子节点，并判断是否符合过滤器的条件。返回值类型是bs4.element.ResultSet。\n  完整的语法：\n  `find_all( name , attrs , recursive , string , **kwargs )`\n\n# 继续之前的爬取\n\n------\n\n我们选中想要爬取的地方，查看html代码。发现游戏的在线人数都在span标签里，并且class都是currentServers，如下图。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322165150.png\" alt=\"QQ截图20210322165150\" style=\"zoom:70%;\" />\n\n通过观察，发现在线人数都在span元素中的文本内容。下面，我们先获取到所有的含有数据的span标签，然后在循环获取span标签中的文本内容。\n\n```python\nimport requests #导入requests 模块\nfrom bs4 import BeautifulSoup  #导入BeautifulSoup 模块\n\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'}  #给请求指定一个请求头来模拟chrome浏览器\nweb_url = 'https://store.steampowered.com/stats/'\nr = requests.get(web_url, headers=headers) #像目标url地址发送get请求，返回一个response对象\nall_a = BeautifulSoup(r.text, 'lxml').find_all('span', class_='currentServers')  #获取网页中的class为currentServers的所有span标签\nfor a in all_a:\n  print(a.string) #循环获取a标签中的style\n```\n\n这里的find_all('span', class_='currentServers')是找到所有class为currentServers的span标签，返回的是一个list，所以可以用for循环获取每个span标签。\n\n力荐[转自[阿里波特]-[Python爬虫小白入门]](https://www.cnblogs.com/Albert-Lee/p/6226699.html)OvO\n\n<img class=\"litimg\" src=\"\\img\\bbe600fa828ba61e7b3276565634970a314e593a.gif\" alt=\"bbe600fa828ba61e7b3276565634970a314e593a\" style=\"zoom:100%;\" />\n\n***`Excalibur！！！`***","source":"_posts/python爬虫-爬取steam统计数据（steam游戏在线人数）（一）.md","raw":"---\ntitle: python爬虫-爬取steam统计数据（steam游戏在线人数）\ndate: 2021-03-22 16:10:24\ntags:\n  - study\n  - python\n---\n\n[转自[阿里波特]-[Python爬虫小白入门]](https://www.cnblogs.com/Albert-Lee/p/6226699.html)\n\n# 前言\n\n------\n\n你是不是在为想收集数据而不知道如何收集而着急？\n\n你是不是在为想学习爬虫而找不到一个专门为小白写的教程而烦恼？\n\nBingo! 你没有看错，这就是专门面向小白学习爬虫而写的！我会采用实例的方式，把每个部分都跟实际的例子结合起来帮助小伙伴儿们理解。最后再写几个实战的例子。\n\n我们使用Python来写爬虫，一方面因为Python是一个特别适合变成入门的语言，另一方面，Python也有很多爬虫相关的工具包，能够简单快速的开发出我们的小爬虫。\n本系列采用Python3.5版本，毕竟2.7会慢慢退出历史舞台~\n\n那么，接下来，你得知道什么是爬虫、爬虫从哪里爬取数据的，以及，学习爬虫都要学习哪些东西。\n\n# 什么是爬虫\n\n------\n\n来看看百度百科是如何定义的\n\n> [网络爬虫](http://baike.baidu.com/view/284853.htm)（又被称为网页[蜘蛛](http://baike.baidu.com/subview/8483/5395928.htm)，网络机器人，在[FOAF](http://baike.baidu.com/view/271451.htm)社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取[万维网](http://baike.baidu.com/view/7833.htm)信息的程序或者脚本。另外一些不常使用的名字还有[蚂蚁](http://baike.baidu.com/subview/3312/6169348.htm)、自动索引、模拟程序或者[蠕虫](http://baike.baidu.com/view/2596.htm)。\n\n什么？没看懂？没关系，我来给你解释一下\n\n打开一个网页，里面有网页内容吧，想象一下，有个工具，可以把网页上的内容获取下来，存到你想要的地方，这个工具就是我们今天的主角：爬虫。\n\n这样是不是更清晰了呢？\n\n既然了解了爬虫是什么，那么爬虫是如何爬取数据的呢？\n\n# 爬虫是哪里爬取数据的\n\n------\n\n打开浏览器（强烈建议谷歌浏览器），找到浏览器地址栏，然后在里输入store.steampowered.com/stats/并回车，你会看到网页内容。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162126.png\" alt=\"QQ截图20210322162126\" style=\"zoom:100%;\" />\n\n摁下键盘上的F12打开开发调试工具,，然后点击元素。看到这些文字了吗？这才是网页最赤果果的样子。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162407.png\" alt=\"QQ截图20210322162407\" style=\"zoom:100%;\" />\n\n其实所有的网页都是HTML代码，只不过浏览器将这些代码解析成了上面的网页，我们的爬虫抓取的其实就是HTML代码中的文本。\n\n随后点击开发调试工具左上角的小鼠标图标，点击你想要爬取的数据，你就会在元素这一栏看到下面红框的地方，是你要爬取数据的本来模样。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162801.png\" alt=\"QQ截图20210322162801\" style=\"zoom:100%;\" />\n\n没错，我们的爬虫抓取的正是网页中的数据，你要知道你想要抓取什么数据，你的目标网站是什么，才可以把想法变成现实的。\n\n# 学习爬虫的必备知识\n\n------\n\n大家要先对以下内容有一定的了解再来学习爬虫哦，磨刀不误砍柴工\n\n- HTML\n  这个能够帮助你了解网页的结构，内容等。可以参考[W3School的教程](http://www.w3school.com.cn/html/index.asp)。\n- Python\n  如果有编程基础的小伙伴儿，推荐看一个[廖雪峰的Python教程](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000)就够了\n  没有编程基础的小伙伴，推荐看看视频教程（网易云课堂搜Python），然后再结合廖雪峰的教程，双管齐下。\n  其实知乎上总结的已经非常好了，我就不多唠叨了。[知乎-如何系统的自学Python](https://www.zhihu.com/question/29138020)\n- TCP/IP协议，HTTP协议\n  这些知识能够让你了解在网络请求和网络传输上的基本原理，了解就行，能够帮助今后写爬虫的时候理解爬虫的逻辑。\n  廖雪峰Python教程里也有简单介绍，可以参考：[TCP/IP简介](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014320037768360d53e4e935ca4a1f96eed1c896ad1217000)，[HTTP协议](http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432011939547478fd5482deb47b08716557cc99764e0000)\n  想更深入学习的小伙伴儿可以去网上多搜搜相关的书籍哦\n\nOK, 下一步就开始我们的实战啦\n\n# requests 库的安装\n\n为什么要先说Requests库呢，因为这是个功能很强大的网络请求库，可以实现跟浏览器一样发送各种HTTP请求来获取网站的数据。网络上的模块、库、包指的都是同一种东西，所以后文中可能会在不同地方使用不同称谓，不要迷惑。\n\n直接使用Python3.5的小伙伴儿输入这个命令：\n`pip install requests`\n\n如果你机器上存在多个Python版本，要给Python3.5的版本安装requests库，需要输入以下命令：\n`py -3 -m pip install requests`\n\n好啦，requests库安装完毕，接下来我们会在实际例子中演示它的使用。想要深入了解requests模块的小伙伴也可以仔细阅读[英文官方文档](http://docs.python-requests.org/en/master/api/)，和[中文官方文档](http://docs.python-requests.org/zh_CN/latest/user/quickstart.html)，如果用到该文没有提到的功能，则查看文档即可。\n\n# 开工\n\n------\n\n新建一个文件，只要他的后缀为.py即可，名字选择你喜欢的就好。\n\n输入第一行代码来导入requests库：\n`import requests #导入requests库`\n\n然后用它来获取咱们的目标网页：\n\n```python\nr = requests.get('https://store.steampowered.com/stats/') #像目标url地址发送get请求，返回一个response对象\nprint(r.text) #r.text是http response的网页HTML\n```\n\n之后再文件目录打开cmd页面，指令运行\n\n`python xxxxx.py`\n\n执行完之后，底部会出现输出结果：\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322163703.png\" alt=\"QQ截图20210322163703\" style=\"zoom:70%;\" />\n\n可以看到底部是获取到的网页内容。这就完成了爬虫的第一步，获取到了网页的HTML内容。\n\n这用到了requests库的get请求。其他请求使用也与之类似，但本文不进行阐述。\n\n我们刚才用requests库发送http请求获得了网页的HTML内容，那么应该如何从HTML中获得图片？\n\nBeautifulSoup库就此登场啦，赶快去来了解它的用法。\n\n刚才演示了如何使用requests模块向网站发送http请求，获取到网页的HTML数据。这篇来演示如何使用BeautifulSoup模块来从HTML文本中提取我们想要的数据。\n\n# 模块安装\n\n------\n\nBeautifulSoup 有多个版本，我们使用BeautifulSoup4。详细使用看[BeautifuSoup4官方文档](http://beautifulsoup.readthedocs.io/zh_CN/latest/)。\n使用管理员权限打开cmd命令窗口，在窗口中输入下面的命令即可安装：\n`pip install beautifulsoup4`\n\n然后我们安装lxml，这是一个解析器，BeautifulSoup可以使用它来解析HTML，然后提取内容。\n\n`pip install lxml`\n\n如果不安装lxml，则BeautifulSoup会使用Python内置的解析器对文档进行解析。之所以使用lxml，是因为它速度快。\n\n# BeautifulSoup 库的使用\n\n------\n\n网上找到的几个官方文档：[BeautifulSoup4.4.0中文官方文档](http://beautifulsoup.readthedocs.io/zh_CN/latest/)，[BeautifulSoup4.2.0中文官方文档](https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/)。不同版本的用法差不多，几个常用的语法都一样。\n\n首先来看BeautifulSoup的对象种类，在使用的过程中就会了解你获取到的东西接下来应该如何操作。\n\n## BeautifulSoup对象的类型\n\nBeautiful Soup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象。所有对象可以归纳为4种类型: Tag , NavigableString , BeautifulSoup , Comment 。下面我们分别看看这四种类型都是什么东西。\n\n### Tag\n\n这个就跟HTML或者XML（还能解析XML？是的，能！）中的标签是一样一样的。我们使用find()方法返回的类型就是这个（插一句：使用find-all()返回的是多个该对象的集合，是可以用for循环遍历的。）。返回标签之后，还可以对提取标签中的信息。\n\n###### 提取标签的名字：\n\n```javascript\ntag.name\n```\n\n###### 提取标签的属性：\n\n```javascript\ntag['attribute']\n```\n\n### NavigableString\n\nNavigableString就是标签中的文本内容（不包含标签）。获取方式如下：\n`tag.string`\n还是以上面那个例子，加上下面这行，然后执行：\n`print('NavigableString is：', find.string)`\n\n### BeautifulSoup\n\nBeautifulSoup对象表示一个文档的全部内容。支持遍历文档树和搜索文档树。\n\n### Comment\n\n这个对象其实就是HTML和XML中的注释。\n\n### 搜索文档树\n\n最常用的当然是find()和find_all()啦，当然还有其他的。比如find_parent() 和 find_parents()、 find_next_sibling() 和 find_next_siblings() 、find_all_next() 和 find_next()、find_all_previous() 和 find_previous() 等等。\n我们就看几个常用的，其余的如果用到就去看官方文档哦。\n\n- find_all()\n  搜索当前tag的所有tag子节点，并判断是否符合过滤器的条件。返回值类型是bs4.element.ResultSet。\n  完整的语法：\n  `find_all( name , attrs , recursive , string , **kwargs )`\n\n# 继续之前的爬取\n\n------\n\n我们选中想要爬取的地方，查看html代码。发现游戏的在线人数都在span标签里，并且class都是currentServers，如下图。\n\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322165150.png\" alt=\"QQ截图20210322165150\" style=\"zoom:70%;\" />\n\n通过观察，发现在线人数都在span元素中的文本内容。下面，我们先获取到所有的含有数据的span标签，然后在循环获取span标签中的文本内容。\n\n```python\nimport requests #导入requests 模块\nfrom bs4 import BeautifulSoup  #导入BeautifulSoup 模块\n\nheaders = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'}  #给请求指定一个请求头来模拟chrome浏览器\nweb_url = 'https://store.steampowered.com/stats/'\nr = requests.get(web_url, headers=headers) #像目标url地址发送get请求，返回一个response对象\nall_a = BeautifulSoup(r.text, 'lxml').find_all('span', class_='currentServers')  #获取网页中的class为currentServers的所有span标签\nfor a in all_a:\n  print(a.string) #循环获取a标签中的style\n```\n\n这里的find_all('span', class_='currentServers')是找到所有class为currentServers的span标签，返回的是一个list，所以可以用for循环获取每个span标签。\n\n力荐[转自[阿里波特]-[Python爬虫小白入门]](https://www.cnblogs.com/Albert-Lee/p/6226699.html)OvO\n\n<img class=\"litimg\" src=\"\\img\\bbe600fa828ba61e7b3276565634970a314e593a.gif\" alt=\"bbe600fa828ba61e7b3276565634970a314e593a\" style=\"zoom:100%;\" />\n\n***`Excalibur！！！`***","slug":"python爬虫-爬取steam统计数据（steam游戏在线人数）（一）","published":1,"updated":"2021-03-23T00:49:55.406Z","_id":"ckmkdd9vw000028vs8k9v9vwu","comments":1,"layout":"post","photos":[],"link":"","content":"<p><a href=\"https://www.cnblogs.com/Albert-Lee/p/6226699.html\">转自[阿里波特]-[Python爬虫小白入门]</a></p>\n<h1><span id=\"前言\">前言</span></h1><hr>\n<p>你是不是在为想收集数据而不知道如何收集而着急？</p>\n<p>你是不是在为想学习爬虫而找不到一个专门为小白写的教程而烦恼？</p>\n<p>Bingo! 你没有看错，这就是专门面向小白学习爬虫而写的！我会采用实例的方式，把每个部分都跟实际的例子结合起来帮助小伙伴儿们理解。最后再写几个实战的例子。</p>\n<p>我们使用Python来写爬虫，一方面因为Python是一个特别适合变成入门的语言，另一方面，Python也有很多爬虫相关的工具包，能够简单快速的开发出我们的小爬虫。<br>本系列采用Python3.5版本，毕竟2.7会慢慢退出历史舞台~</p>\n<p>那么，接下来，你得知道什么是爬虫、爬虫从哪里爬取数据的，以及，学习爬虫都要学习哪些东西。</p>\n<h1><span id=\"什么是爬虫\">什么是爬虫</span></h1><hr>\n<p>来看看百度百科是如何定义的</p>\n<blockquote>\n<p><a href=\"http://baike.baidu.com/view/284853.htm\">网络爬虫</a>（又被称为网页<a href=\"http://baike.baidu.com/subview/8483/5395928.htm\">蜘蛛</a>，网络机器人，在<a href=\"http://baike.baidu.com/view/271451.htm\">FOAF</a>社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取<a href=\"http://baike.baidu.com/view/7833.htm\">万维网</a>信息的程序或者脚本。另外一些不常使用的名字还有<a href=\"http://baike.baidu.com/subview/3312/6169348.htm\">蚂蚁</a>、自动索引、模拟程序或者<a href=\"http://baike.baidu.com/view/2596.htm\">蠕虫</a>。</p>\n</blockquote>\n<p>什么？没看懂？没关系，我来给你解释一下</p>\n<p>打开一个网页，里面有网页内容吧，想象一下，有个工具，可以把网页上的内容获取下来，存到你想要的地方，这个工具就是我们今天的主角：爬虫。</p>\n<p>这样是不是更清晰了呢？</p>\n<p>既然了解了爬虫是什么，那么爬虫是如何爬取数据的呢？</p>\n<h1><span id=\"爬虫是哪里爬取数据的\">爬虫是哪里爬取数据的</span></h1><hr>\n<p>打开浏览器（强烈建议谷歌浏览器），找到浏览器地址栏，然后在里输入store.steampowered.com/stats/并回车，你会看到网页内容。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162126.png\" alt=\"QQ截图20210322162126\" style=\"zoom:100%;\">\n\n<p>摁下键盘上的F12打开开发调试工具,，然后点击元素。看到这些文字了吗？这才是网页最赤果果的样子。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162407.png\" alt=\"QQ截图20210322162407\" style=\"zoom:100%;\">\n\n<p>其实所有的网页都是HTML代码，只不过浏览器将这些代码解析成了上面的网页，我们的爬虫抓取的其实就是HTML代码中的文本。</p>\n<p>随后点击开发调试工具左上角的小鼠标图标，点击你想要爬取的数据，你就会在元素这一栏看到下面红框的地方，是你要爬取数据的本来模样。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162801.png\" alt=\"QQ截图20210322162801\" style=\"zoom:100%;\">\n\n<p>没错，我们的爬虫抓取的正是网页中的数据，你要知道你想要抓取什么数据，你的目标网站是什么，才可以把想法变成现实的。</p>\n<h1><span id=\"学习爬虫的必备知识\">学习爬虫的必备知识</span></h1><hr>\n<p>大家要先对以下内容有一定的了解再来学习爬虫哦，磨刀不误砍柴工</p>\n<ul>\n<li>HTML<br>这个能够帮助你了解网页的结构，内容等。可以参考<a href=\"http://www.w3school.com.cn/html/index.asp\">W3School的教程</a>。</li>\n<li>Python<br>如果有编程基础的小伙伴儿，推荐看一个<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000\">廖雪峰的Python教程</a>就够了<br>没有编程基础的小伙伴，推荐看看视频教程（网易云课堂搜Python），然后再结合廖雪峰的教程，双管齐下。<br>其实知乎上总结的已经非常好了，我就不多唠叨了。<a href=\"https://www.zhihu.com/question/29138020\">知乎-如何系统的自学Python</a></li>\n<li>TCP/IP协议，HTTP协议<br>这些知识能够让你了解在网络请求和网络传输上的基本原理，了解就行，能够帮助今后写爬虫的时候理解爬虫的逻辑。<br>廖雪峰Python教程里也有简单介绍，可以参考：<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014320037768360d53e4e935ca4a1f96eed1c896ad1217000\">TCP/IP简介</a>，<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432011939547478fd5482deb47b08716557cc99764e0000\">HTTP协议</a><br>想更深入学习的小伙伴儿可以去网上多搜搜相关的书籍哦</li>\n</ul>\n<p>OK, 下一步就开始我们的实战啦</p>\n<h1><span id=\"requests-库的安装\">requests 库的安装</span></h1><p>为什么要先说Requests库呢，因为这是个功能很强大的网络请求库，可以实现跟浏览器一样发送各种HTTP请求来获取网站的数据。网络上的模块、库、包指的都是同一种东西，所以后文中可能会在不同地方使用不同称谓，不要迷惑。</p>\n<p>直接使用Python3.5的小伙伴儿输入这个命令：<br><code>pip install requests</code></p>\n<p>如果你机器上存在多个Python版本，要给Python3.5的版本安装requests库，需要输入以下命令：<br><code>py -3 -m pip install requests</code></p>\n<p>好啦，requests库安装完毕，接下来我们会在实际例子中演示它的使用。想要深入了解requests模块的小伙伴也可以仔细阅读<a href=\"http://docs.python-requests.org/en/master/api/\">英文官方文档</a>，和<a href=\"http://docs.python-requests.org/zh_CN/latest/user/quickstart.html\">中文官方文档</a>，如果用到该文没有提到的功能，则查看文档即可。</p>\n<h1><span id=\"开工\">开工</span></h1><hr>\n<p>新建一个文件，只要他的后缀为.py即可，名字选择你喜欢的就好。</p>\n<p>输入第一行代码来导入requests库：<br><code>import requests #导入requests库</code></p>\n<p>然后用它来获取咱们的目标网页：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = requests.get(<span class=\"string\">&#x27;https://store.steampowered.com/stats/&#x27;</span>) <span class=\"comment\">#像目标url地址发送get请求，返回一个response对象</span></span><br><span class=\"line\">print(r.text) <span class=\"comment\">#r.text是http response的网页HTML</span></span><br></pre></td></tr></table></figure>\n\n<p>之后再文件目录打开cmd页面，指令运行</p>\n<p><code>python xxxxx.py</code></p>\n<p>执行完之后，底部会出现输出结果：</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322163703.png\" alt=\"QQ截图20210322163703\" style=\"zoom:70%;\">\n\n<p>可以看到底部是获取到的网页内容。这就完成了爬虫的第一步，获取到了网页的HTML内容。</p>\n<p>这用到了requests库的get请求。其他请求使用也与之类似，但本文不进行阐述。</p>\n<p>我们刚才用requests库发送http请求获得了网页的HTML内容，那么应该如何从HTML中获得图片？</p>\n<p>BeautifulSoup库就此登场啦，赶快去来了解它的用法。</p>\n<p>刚才演示了如何使用requests模块向网站发送http请求，获取到网页的HTML数据。这篇来演示如何使用BeautifulSoup模块来从HTML文本中提取我们想要的数据。</p>\n<h1><span id=\"模块安装\">模块安装</span></h1><hr>\n<p>BeautifulSoup 有多个版本，我们使用BeautifulSoup4。详细使用看<a href=\"http://beautifulsoup.readthedocs.io/zh_CN/latest/\">BeautifuSoup4官方文档</a>。<br>使用管理员权限打开cmd命令窗口，在窗口中输入下面的命令即可安装：<br><code>pip install beautifulsoup4</code></p>\n<p>然后我们安装lxml，这是一个解析器，BeautifulSoup可以使用它来解析HTML，然后提取内容。</p>\n<p><code>pip install lxml</code></p>\n<p>如果不安装lxml，则BeautifulSoup会使用Python内置的解析器对文档进行解析。之所以使用lxml，是因为它速度快。</p>\n<h1><span id=\"beautifulsoup-库的使用\">BeautifulSoup 库的使用</span></h1><hr>\n<p>网上找到的几个官方文档：<a href=\"http://beautifulsoup.readthedocs.io/zh_CN/latest/\">BeautifulSoup4.4.0中文官方文档</a>，<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/\">BeautifulSoup4.2.0中文官方文档</a>。不同版本的用法差不多，几个常用的语法都一样。</p>\n<p>首先来看BeautifulSoup的对象种类，在使用的过程中就会了解你获取到的东西接下来应该如何操作。</p>\n<h2><span id=\"beautifulsoup对象的类型\">BeautifulSoup对象的类型</span></h2><p>Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象。所有对象可以归纳为4种类型: Tag , NavigableString , BeautifulSoup , Comment 。下面我们分别看看这四种类型都是什么东西。</p>\n<h3><span id=\"tag\">Tag</span></h3><p>这个就跟HTML或者XML（还能解析XML？是的，能！）中的标签是一样一样的。我们使用find()方法返回的类型就是这个（插一句：使用find-all()返回的是多个该对象的集合，是可以用for循环遍历的。）。返回标签之后，还可以对提取标签中的信息。</p>\n<h6><span id=\"提取标签的名字\">提取标签的名字：</span></h6><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tag.name</span><br></pre></td></tr></table></figure>\n\n<h6><span id=\"提取标签的属性\">提取标签的属性：</span></h6><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tag[<span class=\"string\">&#x27;attribute&#x27;</span>]</span><br></pre></td></tr></table></figure>\n\n<h3><span id=\"navigablestring\">NavigableString</span></h3><p>NavigableString就是标签中的文本内容（不包含标签）。获取方式如下：<br><code>tag.string</code><br>还是以上面那个例子，加上下面这行，然后执行：<br><code>print(&#39;NavigableString is：&#39;, find.string)</code></p>\n<h3><span id=\"beautifulsoup\">BeautifulSoup</span></h3><p>BeautifulSoup对象表示一个文档的全部内容。支持遍历文档树和搜索文档树。</p>\n<h3><span id=\"comment\">Comment</span></h3><p>这个对象其实就是HTML和XML中的注释。</p>\n<h3><span id=\"搜索文档树\">搜索文档树</span></h3><p>最常用的当然是find()和find_all()啦，当然还有其他的。比如find_parent() 和 find_parents()、 find_next_sibling() 和 find_next_siblings() 、find_all_next() 和 find_next()、find_all_previous() 和 find_previous() 等等。<br>我们就看几个常用的，其余的如果用到就去看官方文档哦。</p>\n<ul>\n<li>find_all()<br>搜索当前tag的所有tag子节点，并判断是否符合过滤器的条件。返回值类型是bs4.element.ResultSet。<br>完整的语法：<br><code>find_all( name , attrs , recursive , string , **kwargs )</code></li>\n</ul>\n<h1><span id=\"继续之前的爬取\">继续之前的爬取</span></h1><hr>\n<p>我们选中想要爬取的地方，查看html代码。发现游戏的在线人数都在span标签里，并且class都是currentServers，如下图。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322165150.png\" alt=\"QQ截图20210322165150\" style=\"zoom:70%;\">\n\n<p>通过观察，发现在线人数都在span元素中的文本内容。下面，我们先获取到所有的含有数据的span标签，然后在循环获取span标签中的文本内容。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"comment\">#导入requests 模块</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup  <span class=\"comment\">#导入BeautifulSoup 模块</span></span><br><span class=\"line\"></span><br><span class=\"line\">headers = &#123;<span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&#x27;</span>&#125;  <span class=\"comment\">#给请求指定一个请求头来模拟chrome浏览器</span></span><br><span class=\"line\">web_url = <span class=\"string\">&#x27;https://store.steampowered.com/stats/&#x27;</span></span><br><span class=\"line\">r = requests.get(web_url, headers=headers) <span class=\"comment\">#像目标url地址发送get请求，返回一个response对象</span></span><br><span class=\"line\">all_a = BeautifulSoup(r.text, <span class=\"string\">&#x27;lxml&#x27;</span>).find_all(<span class=\"string\">&#x27;span&#x27;</span>, class_=<span class=\"string\">&#x27;currentServers&#x27;</span>)  <span class=\"comment\">#获取网页中的class为currentServers的所有span标签</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> all_a:</span><br><span class=\"line\">  print(a.string) <span class=\"comment\">#循环获取a标签中的style</span></span><br></pre></td></tr></table></figure>\n\n<p>这里的find_all(‘span’, class_=’currentServers’)是找到所有class为currentServers的span标签，返回的是一个list，所以可以用for循环获取每个span标签。</p>\n<p>力荐<a href=\"https://www.cnblogs.com/Albert-Lee/p/6226699.html\">转自[阿里波特]-[Python爬虫小白入门]</a>OvO</p>\n<img class=\"litimg\" src=\"\\img\\bbe600fa828ba61e7b3276565634970a314e593a.gif\" alt=\"bbe600fa828ba61e7b3276565634970a314e593a\" style=\"zoom:100%;\">\n\n<p><em><strong><code>Excalibur！！！</code></strong></em></p>\n","site":{"data":{}},"excerpt":"","more":"<p><a href=\"https://www.cnblogs.com/Albert-Lee/p/6226699.html\">转自[阿里波特]-[Python爬虫小白入门]</a></p>\n<h1 id=\"前言\"><a href=\"#前言\" class=\"headerlink\" title=\"前言\"></a>前言</h1><hr>\n<p>你是不是在为想收集数据而不知道如何收集而着急？</p>\n<p>你是不是在为想学习爬虫而找不到一个专门为小白写的教程而烦恼？</p>\n<p>Bingo! 你没有看错，这就是专门面向小白学习爬虫而写的！我会采用实例的方式，把每个部分都跟实际的例子结合起来帮助小伙伴儿们理解。最后再写几个实战的例子。</p>\n<p>我们使用Python来写爬虫，一方面因为Python是一个特别适合变成入门的语言，另一方面，Python也有很多爬虫相关的工具包，能够简单快速的开发出我们的小爬虫。<br>本系列采用Python3.5版本，毕竟2.7会慢慢退出历史舞台~</p>\n<p>那么，接下来，你得知道什么是爬虫、爬虫从哪里爬取数据的，以及，学习爬虫都要学习哪些东西。</p>\n<h1 id=\"什么是爬虫\"><a href=\"#什么是爬虫\" class=\"headerlink\" title=\"什么是爬虫\"></a>什么是爬虫</h1><hr>\n<p>来看看百度百科是如何定义的</p>\n<blockquote>\n<p><a href=\"http://baike.baidu.com/view/284853.htm\">网络爬虫</a>（又被称为网页<a href=\"http://baike.baidu.com/subview/8483/5395928.htm\">蜘蛛</a>，网络机器人，在<a href=\"http://baike.baidu.com/view/271451.htm\">FOAF</a>社区中间，更经常的称为网页追逐者），是一种按照一定的规则，自动地抓取<a href=\"http://baike.baidu.com/view/7833.htm\">万维网</a>信息的程序或者脚本。另外一些不常使用的名字还有<a href=\"http://baike.baidu.com/subview/3312/6169348.htm\">蚂蚁</a>、自动索引、模拟程序或者<a href=\"http://baike.baidu.com/view/2596.htm\">蠕虫</a>。</p>\n</blockquote>\n<p>什么？没看懂？没关系，我来给你解释一下</p>\n<p>打开一个网页，里面有网页内容吧，想象一下，有个工具，可以把网页上的内容获取下来，存到你想要的地方，这个工具就是我们今天的主角：爬虫。</p>\n<p>这样是不是更清晰了呢？</p>\n<p>既然了解了爬虫是什么，那么爬虫是如何爬取数据的呢？</p>\n<h1 id=\"爬虫是哪里爬取数据的\"><a href=\"#爬虫是哪里爬取数据的\" class=\"headerlink\" title=\"爬虫是哪里爬取数据的\"></a>爬虫是哪里爬取数据的</h1><hr>\n<p>打开浏览器（强烈建议谷歌浏览器），找到浏览器地址栏，然后在里输入store.steampowered.com/stats/并回车，你会看到网页内容。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162126.png\" alt=\"QQ截图20210322162126\" style=\"zoom:100%;\" />\n\n<p>摁下键盘上的F12打开开发调试工具,，然后点击元素。看到这些文字了吗？这才是网页最赤果果的样子。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162407.png\" alt=\"QQ截图20210322162407\" style=\"zoom:100%;\" />\n\n<p>其实所有的网页都是HTML代码，只不过浏览器将这些代码解析成了上面的网页，我们的爬虫抓取的其实就是HTML代码中的文本。</p>\n<p>随后点击开发调试工具左上角的小鼠标图标，点击你想要爬取的数据，你就会在元素这一栏看到下面红框的地方，是你要爬取数据的本来模样。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322162801.png\" alt=\"QQ截图20210322162801\" style=\"zoom:100%;\" />\n\n<p>没错，我们的爬虫抓取的正是网页中的数据，你要知道你想要抓取什么数据，你的目标网站是什么，才可以把想法变成现实的。</p>\n<h1 id=\"学习爬虫的必备知识\"><a href=\"#学习爬虫的必备知识\" class=\"headerlink\" title=\"学习爬虫的必备知识\"></a>学习爬虫的必备知识</h1><hr>\n<p>大家要先对以下内容有一定的了解再来学习爬虫哦，磨刀不误砍柴工</p>\n<ul>\n<li>HTML<br>这个能够帮助你了解网页的结构，内容等。可以参考<a href=\"http://www.w3school.com.cn/html/index.asp\">W3School的教程</a>。</li>\n<li>Python<br>如果有编程基础的小伙伴儿，推荐看一个<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000\">廖雪峰的Python教程</a>就够了<br>没有编程基础的小伙伴，推荐看看视频教程（网易云课堂搜Python），然后再结合廖雪峰的教程，双管齐下。<br>其实知乎上总结的已经非常好了，我就不多唠叨了。<a href=\"https://www.zhihu.com/question/29138020\">知乎-如何系统的自学Python</a></li>\n<li>TCP/IP协议，HTTP协议<br>这些知识能够让你了解在网络请求和网络传输上的基本原理，了解就行，能够帮助今后写爬虫的时候理解爬虫的逻辑。<br>廖雪峰Python教程里也有简单介绍，可以参考：<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/0014320037768360d53e4e935ca4a1f96eed1c896ad1217000\">TCP/IP简介</a>，<a href=\"http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001432011939547478fd5482deb47b08716557cc99764e0000\">HTTP协议</a><br>想更深入学习的小伙伴儿可以去网上多搜搜相关的书籍哦</li>\n</ul>\n<p>OK, 下一步就开始我们的实战啦</p>\n<h1 id=\"requests-库的安装\"><a href=\"#requests-库的安装\" class=\"headerlink\" title=\"requests 库的安装\"></a>requests 库的安装</h1><p>为什么要先说Requests库呢，因为这是个功能很强大的网络请求库，可以实现跟浏览器一样发送各种HTTP请求来获取网站的数据。网络上的模块、库、包指的都是同一种东西，所以后文中可能会在不同地方使用不同称谓，不要迷惑。</p>\n<p>直接使用Python3.5的小伙伴儿输入这个命令：<br><code>pip install requests</code></p>\n<p>如果你机器上存在多个Python版本，要给Python3.5的版本安装requests库，需要输入以下命令：<br><code>py -3 -m pip install requests</code></p>\n<p>好啦，requests库安装完毕，接下来我们会在实际例子中演示它的使用。想要深入了解requests模块的小伙伴也可以仔细阅读<a href=\"http://docs.python-requests.org/en/master/api/\">英文官方文档</a>，和<a href=\"http://docs.python-requests.org/zh_CN/latest/user/quickstart.html\">中文官方文档</a>，如果用到该文没有提到的功能，则查看文档即可。</p>\n<h1 id=\"开工\"><a href=\"#开工\" class=\"headerlink\" title=\"开工\"></a>开工</h1><hr>\n<p>新建一个文件，只要他的后缀为.py即可，名字选择你喜欢的就好。</p>\n<p>输入第一行代码来导入requests库：<br><code>import requests #导入requests库</code></p>\n<p>然后用它来获取咱们的目标网页：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">r = requests.get(<span class=\"string\">&#x27;https://store.steampowered.com/stats/&#x27;</span>) <span class=\"comment\">#像目标url地址发送get请求，返回一个response对象</span></span><br><span class=\"line\">print(r.text) <span class=\"comment\">#r.text是http response的网页HTML</span></span><br></pre></td></tr></table></figure>\n\n<p>之后再文件目录打开cmd页面，指令运行</p>\n<p><code>python xxxxx.py</code></p>\n<p>执行完之后，底部会出现输出结果：</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322163703.png\" alt=\"QQ截图20210322163703\" style=\"zoom:70%;\" />\n\n<p>可以看到底部是获取到的网页内容。这就完成了爬虫的第一步，获取到了网页的HTML内容。</p>\n<p>这用到了requests库的get请求。其他请求使用也与之类似，但本文不进行阐述。</p>\n<p>我们刚才用requests库发送http请求获得了网页的HTML内容，那么应该如何从HTML中获得图片？</p>\n<p>BeautifulSoup库就此登场啦，赶快去来了解它的用法。</p>\n<p>刚才演示了如何使用requests模块向网站发送http请求，获取到网页的HTML数据。这篇来演示如何使用BeautifulSoup模块来从HTML文本中提取我们想要的数据。</p>\n<h1 id=\"模块安装\"><a href=\"#模块安装\" class=\"headerlink\" title=\"模块安装\"></a>模块安装</h1><hr>\n<p>BeautifulSoup 有多个版本，我们使用BeautifulSoup4。详细使用看<a href=\"http://beautifulsoup.readthedocs.io/zh_CN/latest/\">BeautifuSoup4官方文档</a>。<br>使用管理员权限打开cmd命令窗口，在窗口中输入下面的命令即可安装：<br><code>pip install beautifulsoup4</code></p>\n<p>然后我们安装lxml，这是一个解析器，BeautifulSoup可以使用它来解析HTML，然后提取内容。</p>\n<p><code>pip install lxml</code></p>\n<p>如果不安装lxml，则BeautifulSoup会使用Python内置的解析器对文档进行解析。之所以使用lxml，是因为它速度快。</p>\n<h1 id=\"BeautifulSoup-库的使用\"><a href=\"#BeautifulSoup-库的使用\" class=\"headerlink\" title=\"BeautifulSoup 库的使用\"></a>BeautifulSoup 库的使用</h1><hr>\n<p>网上找到的几个官方文档：<a href=\"http://beautifulsoup.readthedocs.io/zh_CN/latest/\">BeautifulSoup4.4.0中文官方文档</a>，<a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc.zh/\">BeautifulSoup4.2.0中文官方文档</a>。不同版本的用法差不多，几个常用的语法都一样。</p>\n<p>首先来看BeautifulSoup的对象种类，在使用的过程中就会了解你获取到的东西接下来应该如何操作。</p>\n<h2 id=\"BeautifulSoup对象的类型\"><a href=\"#BeautifulSoup对象的类型\" class=\"headerlink\" title=\"BeautifulSoup对象的类型\"></a>BeautifulSoup对象的类型</h2><p>Beautiful Soup将复杂HTML文档转换成一个复杂的树形结构，每个节点都是Python对象。所有对象可以归纳为4种类型: Tag , NavigableString , BeautifulSoup , Comment 。下面我们分别看看这四种类型都是什么东西。</p>\n<h3 id=\"Tag\"><a href=\"#Tag\" class=\"headerlink\" title=\"Tag\"></a>Tag</h3><p>这个就跟HTML或者XML（还能解析XML？是的，能！）中的标签是一样一样的。我们使用find()方法返回的类型就是这个（插一句：使用find-all()返回的是多个该对象的集合，是可以用for循环遍历的。）。返回标签之后，还可以对提取标签中的信息。</p>\n<h6 id=\"提取标签的名字：\"><a href=\"#提取标签的名字：\" class=\"headerlink\" title=\"提取标签的名字：\"></a>提取标签的名字：</h6><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tag.name</span><br></pre></td></tr></table></figure>\n\n<h6 id=\"提取标签的属性：\"><a href=\"#提取标签的属性：\" class=\"headerlink\" title=\"提取标签的属性：\"></a>提取标签的属性：</h6><figure class=\"highlight javascript\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tag[<span class=\"string\">&#x27;attribute&#x27;</span>]</span><br></pre></td></tr></table></figure>\n\n<h3 id=\"NavigableString\"><a href=\"#NavigableString\" class=\"headerlink\" title=\"NavigableString\"></a>NavigableString</h3><p>NavigableString就是标签中的文本内容（不包含标签）。获取方式如下：<br><code>tag.string</code><br>还是以上面那个例子，加上下面这行，然后执行：<br><code>print(&#39;NavigableString is：&#39;, find.string)</code></p>\n<h3 id=\"BeautifulSoup\"><a href=\"#BeautifulSoup\" class=\"headerlink\" title=\"BeautifulSoup\"></a>BeautifulSoup</h3><p>BeautifulSoup对象表示一个文档的全部内容。支持遍历文档树和搜索文档树。</p>\n<h3 id=\"Comment\"><a href=\"#Comment\" class=\"headerlink\" title=\"Comment\"></a>Comment</h3><p>这个对象其实就是HTML和XML中的注释。</p>\n<h3 id=\"搜索文档树\"><a href=\"#搜索文档树\" class=\"headerlink\" title=\"搜索文档树\"></a>搜索文档树</h3><p>最常用的当然是find()和find_all()啦，当然还有其他的。比如find_parent() 和 find_parents()、 find_next_sibling() 和 find_next_siblings() 、find_all_next() 和 find_next()、find_all_previous() 和 find_previous() 等等。<br>我们就看几个常用的，其余的如果用到就去看官方文档哦。</p>\n<ul>\n<li>find_all()<br>搜索当前tag的所有tag子节点，并判断是否符合过滤器的条件。返回值类型是bs4.element.ResultSet。<br>完整的语法：<br><code>find_all( name , attrs , recursive , string , **kwargs )</code></li>\n</ul>\n<h1 id=\"继续之前的爬取\"><a href=\"#继续之前的爬取\" class=\"headerlink\" title=\"继续之前的爬取\"></a>继续之前的爬取</h1><hr>\n<p>我们选中想要爬取的地方，查看html代码。发现游戏的在线人数都在span标签里，并且class都是currentServers，如下图。</p>\n<img class=\"litimg\" src=\"\\img\\QQ截图20210322165150.png\" alt=\"QQ截图20210322165150\" style=\"zoom:70%;\" />\n\n<p>通过观察，发现在线人数都在span元素中的文本内容。下面，我们先获取到所有的含有数据的span标签，然后在循环获取span标签中的文本内容。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> requests <span class=\"comment\">#导入requests 模块</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> bs4 <span class=\"keyword\">import</span> BeautifulSoup  <span class=\"comment\">#导入BeautifulSoup 模块</span></span><br><span class=\"line\"></span><br><span class=\"line\">headers = &#123;<span class=\"string\">&#x27;User-Agent&#x27;</span>: <span class=\"string\">&#x27;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36&#x27;</span>&#125;  <span class=\"comment\">#给请求指定一个请求头来模拟chrome浏览器</span></span><br><span class=\"line\">web_url = <span class=\"string\">&#x27;https://store.steampowered.com/stats/&#x27;</span></span><br><span class=\"line\">r = requests.get(web_url, headers=headers) <span class=\"comment\">#像目标url地址发送get请求，返回一个response对象</span></span><br><span class=\"line\">all_a = BeautifulSoup(r.text, <span class=\"string\">&#x27;lxml&#x27;</span>).find_all(<span class=\"string\">&#x27;span&#x27;</span>, class_=<span class=\"string\">&#x27;currentServers&#x27;</span>)  <span class=\"comment\">#获取网页中的class为currentServers的所有span标签</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> a <span class=\"keyword\">in</span> all_a:</span><br><span class=\"line\">  print(a.string) <span class=\"comment\">#循环获取a标签中的style</span></span><br></pre></td></tr></table></figure>\n\n<p>这里的find_all(‘span’, class_=’currentServers’)是找到所有class为currentServers的span标签，返回的是一个list，所以可以用for循环获取每个span标签。</p>\n<p>力荐<a href=\"https://www.cnblogs.com/Albert-Lee/p/6226699.html\">转自[阿里波特]-[Python爬虫小白入门]</a>OvO</p>\n<img class=\"litimg\" src=\"\\img\\bbe600fa828ba61e7b3276565634970a314e593a.gif\" alt=\"bbe600fa828ba61e7b3276565634970a314e593a\" style=\"zoom:100%;\" />\n\n<p><em><strong><code>Excalibur！！！</code></strong></em></p>\n"}],"PostAsset":[],"PostCategory":[],"PostTag":[{"post_id":"ckmk0rez80008ekvs19j32w9k","tag_id":"ckmk0rez10006ekvsgblq5r66","_id":"ckmk0reza000bekvs01vq6uv9"},{"post_id":"ckmk0reyz0004ekvs8g2thay5","tag_id":"ckmk0rez10006ekvsgblq5r66","_id":"ckmk0reza000cekvs6rk2g008"},{"post_id":"ckmk0rez90009ekvsd6tn2rev","tag_id":"ckmk0rez10006ekvsgblq5r66","_id":"ckmk0rezb000dekvs9eejcjhj"},{"post_id":"ckmk0rez40007ekvs9t9r6jnh","tag_id":"ckmk0rez9000aekvs34f9byq7","_id":"ckmk0rezb000eekvs7c89b0ev"},{"post_id":"ckmk1092q0000qwvsg0cf1jaq","tag_id":"ckmk0rez9000aekvs34f9byq7","_id":"ckmk1092v0001qwvs66ne9ooc"},{"post_id":"ckmk0rez00005ekvsa6hh8o2s","tag_id":"ckmk0rez9000aekvs34f9byq7","_id":"ckmk7uule0000lkvsg0fz8jry"},{"post_id":"ckmk0rez80008ekvs19j32w9k","tag_id":"ckmkb2ths0000acvs6btphd0q","_id":"ckmkb2thu0001acvsf4fgcvu0"},{"post_id":"ckmk0rez90009ekvsd6tn2rev","tag_id":"ckmkb2ths0000acvs6btphd0q","_id":"ckmkb2vvm0002acvs5kbs5yle"},{"post_id":"ckmk0reyz0004ekvs8g2thay5","tag_id":"ckmkb2yl30003acvs5ag9h6dx","_id":"ckmkb2yl30004acvs6q6a6bhn"},{"post_id":"ckmkdd9vw000028vs8k9v9vwu","tag_id":"ckmk0rez10006ekvsgblq5r66","_id":"ckmkdd9w1000228vsafuw8xqu"},{"post_id":"ckmkdd9vw000028vs8k9v9vwu","tag_id":"ckmkdd9vy000128vs6fp317qj","_id":"ckmkdd9w1000328vsbj2m7sqf"}],"Tag":[{"name":"study","_id":"ckmk0rez10006ekvsgblq5r66"},{"name":"life","_id":"ckmk0rez9000aekvs34f9byq7"},{"name":"sql","_id":"ckmkb2ths0000acvs6btphd0q"},{"name":"ds","_id":"ckmkb2yl30003acvs5ag9h6dx"},{"name":"python","_id":"ckmkdd9vy000128vs6fp317qj"}]}}